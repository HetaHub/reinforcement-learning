{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153879a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, gym.spaces\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54234f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#other parameters are randomize and won't do customization\n",
    "#hidden layers neurons number, number of episodes for every loop\n",
    "#filter percentage for the best episodes(we will take the best 30%)\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "PERCENTILE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299ec49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8431d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define 2 helper class to create 2 namedtuple.\n",
    "#EpisodeStep store 1 step in a episode, it also stored observation from environment and the action performed\n",
    "#Episode is the set of EpisodeStep, it store the non-discounted reward in one whole episode\n",
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c254f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(env, net, batch_size):\n",
    "    #batch to save result of process, set a reward counter for the current episode\n",
    "    #reset environment and construct softmax layer, it transfer the output to action probabilites\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    \n",
    "    #every loop will convert observation to pytorch tensor and send to network to get the action probability\n",
    "    #nn.Module will get observation value from the CartPole 1 * 4 Tensor\n",
    "    #Because we didn't use softmax function at final layer, it will output original value\n",
    "    while True:\n",
    "        obs_v = torch.FloatTensor([obs])\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        #we use tensor.data to uncompress tensor and convert to Numpy array, this has same 2 dimension as input data\n",
    "        #we want to get the first batch from the batch array, therefore we use [0], which is action probabilities\n",
    "        act_probs = act_probs_v.data.numpy()[0]\n",
    "        \n",
    "        #we use random.choice() to sample from action probabilities, and put the action to environment to get next \n",
    "        #observation, reward and episode is done or not\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        next_obs, reward, is_done, _ = env.step(action)\n",
    "        \n",
    "        #we add the reward to total reward, we store the observation and action pair into the episode_steps, the \n",
    "        #observation is before action, not after\n",
    "        episode_reward += reward\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
    "        \n",
    "        #when gameover, episode is done, we will append the reward to total reward and reset environment and episode rewards\n",
    "        #if batch accumulates enough episodes,we yield the result to caller for further process\n",
    "        if is_done:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        \n",
    "        #get observation value from environment to current observation variable\n",
    "        #repeat everything after: pass observation result to network, sample action and take action, let environment\n",
    "        #handle action, save result\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fbec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def filter_batch(batch, percentile):\n",
    "    #we use numpy percentile to caluclate the reward_bound with the batch reward we got\n",
    "    rewards = list(map(lambda s: s.reward, batch))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    #reward_mean for monitoring\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "    \n",
    "    #if reward is larger than reward boundary, we keep it and store the observation and action\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    for example in batch:\n",
    "        if example.reward < reward_bound:\n",
    "            continue\n",
    "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "        train_act.extend(map(lambda step: step.action, example.steps))\n",
    "        \n",
    "    #transform observation and action to vector and put in array, last 2 will just put in TensorBoard for monitoring but \n",
    "    # no real use\n",
    "    train_obs_v = torch.FloatTensor(train_obs)\n",
    "    train_act_v = torch.LongTensor(train_act)\n",
    "    return train_obs_v, train_act_v, reward_bound, reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2993dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteOneHotWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(DiscreteOneHotWrapper, self).__init__(env)\n",
    "        assert isinstance(env.observation_space, gym.spaces.Discrete)\n",
    "        self.observation_space = gym.spaces.Box(0.0, 1.0, (env.observation_space.n, ), dtype=np.float32)\n",
    "        \n",
    "    def observation(self, observation):\n",
    "        res = np.copy(self.observation_space.low)\n",
    "        res[observation] = 1.0\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885ba79",
   "metadata": {},
   "source": [
    "# The reward cannot converge because the environment and reward mechanism is very different, the reward will mark as success(1) or fail(0), and we only have very little chance by random walking will go to the goal. So if we use >50-70% as elite episode for training, probably there are many failed episodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff53bd",
   "metadata": {},
   "source": [
    "# To conclude, if using cross entropy, the episode is shorter, the result is better. The total reward should be able to divide the good and bad episode. Also before success, there won't be any indication of whether the target is going to achieve as good episode or bad episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c19fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=1.383, reward_mean=0.1, reward_bound=0.0\n",
      "1: loss=1.413, reward_mean=0.0, reward_bound=0.0\n",
      "2: loss=1.401, reward_mean=0.0, reward_bound=0.0\n",
      "3: loss=1.383, reward_mean=0.0, reward_bound=0.0\n",
      "4: loss=1.357, reward_mean=0.0, reward_bound=0.0\n",
      "5: loss=1.355, reward_mean=0.0, reward_bound=0.0\n",
      "6: loss=1.406, reward_mean=0.0, reward_bound=0.0\n",
      "7: loss=1.382, reward_mean=0.0, reward_bound=0.0\n",
      "8: loss=1.376, reward_mean=0.1, reward_bound=0.0\n",
      "9: loss=1.355, reward_mean=0.0, reward_bound=0.0\n",
      "10: loss=1.377, reward_mean=0.1, reward_bound=0.0\n",
      "11: loss=1.376, reward_mean=0.1, reward_bound=0.0\n",
      "12: loss=1.382, reward_mean=0.0, reward_bound=0.0\n",
      "13: loss=1.310, reward_mean=0.1, reward_bound=0.0\n",
      "14: loss=1.346, reward_mean=0.0, reward_bound=0.0\n",
      "15: loss=1.351, reward_mean=0.0, reward_bound=0.0\n",
      "16: loss=1.337, reward_mean=0.0, reward_bound=0.0\n",
      "17: loss=1.390, reward_mean=0.1, reward_bound=0.0\n",
      "18: loss=1.371, reward_mean=0.0, reward_bound=0.0\n",
      "19: loss=1.317, reward_mean=0.0, reward_bound=0.0\n",
      "20: loss=1.317, reward_mean=0.1, reward_bound=0.0\n",
      "21: loss=1.359, reward_mean=0.1, reward_bound=0.0\n",
      "22: loss=1.321, reward_mean=0.0, reward_bound=0.0\n",
      "23: loss=1.277, reward_mean=0.1, reward_bound=0.0\n",
      "24: loss=1.334, reward_mean=0.0, reward_bound=0.0\n",
      "25: loss=1.353, reward_mean=0.0, reward_bound=0.0\n",
      "26: loss=1.295, reward_mean=0.0, reward_bound=0.0\n",
      "27: loss=1.281, reward_mean=0.0, reward_bound=0.0\n",
      "28: loss=1.287, reward_mean=0.0, reward_bound=0.0\n",
      "29: loss=1.328, reward_mean=0.0, reward_bound=0.0\n",
      "30: loss=1.298, reward_mean=0.1, reward_bound=0.0\n",
      "31: loss=1.243, reward_mean=0.0, reward_bound=0.0\n",
      "32: loss=1.326, reward_mean=0.1, reward_bound=0.0\n",
      "33: loss=1.247, reward_mean=0.1, reward_bound=0.0\n",
      "34: loss=1.312, reward_mean=0.0, reward_bound=0.0\n",
      "35: loss=1.256, reward_mean=0.0, reward_bound=0.0\n",
      "36: loss=1.281, reward_mean=0.1, reward_bound=0.0\n",
      "37: loss=1.183, reward_mean=0.0, reward_bound=0.0\n",
      "38: loss=1.187, reward_mean=0.1, reward_bound=0.0\n",
      "39: loss=1.188, reward_mean=0.1, reward_bound=0.0\n",
      "40: loss=1.326, reward_mean=0.0, reward_bound=0.0\n",
      "41: loss=1.240, reward_mean=0.0, reward_bound=0.0\n",
      "42: loss=1.313, reward_mean=0.1, reward_bound=0.0\n",
      "43: loss=1.124, reward_mean=0.0, reward_bound=0.0\n",
      "44: loss=1.229, reward_mean=0.1, reward_bound=0.0\n",
      "45: loss=1.226, reward_mean=0.0, reward_bound=0.0\n",
      "46: loss=1.179, reward_mean=0.0, reward_bound=0.0\n",
      "47: loss=1.179, reward_mean=0.0, reward_bound=0.0\n",
      "48: loss=1.250, reward_mean=0.1, reward_bound=0.0\n",
      "49: loss=1.224, reward_mean=0.0, reward_bound=0.0\n",
      "50: loss=1.229, reward_mean=0.1, reward_bound=0.0\n",
      "51: loss=1.111, reward_mean=0.0, reward_bound=0.0\n",
      "52: loss=1.169, reward_mean=0.0, reward_bound=0.0\n",
      "53: loss=1.104, reward_mean=0.1, reward_bound=0.0\n",
      "54: loss=1.162, reward_mean=0.0, reward_bound=0.0\n",
      "55: loss=1.108, reward_mean=0.0, reward_bound=0.0\n",
      "56: loss=1.097, reward_mean=0.0, reward_bound=0.0\n",
      "57: loss=1.101, reward_mean=0.0, reward_bound=0.0\n",
      "58: loss=1.182, reward_mean=0.1, reward_bound=0.0\n",
      "59: loss=1.018, reward_mean=0.0, reward_bound=0.0\n",
      "60: loss=1.045, reward_mean=0.0, reward_bound=0.0\n",
      "61: loss=0.925, reward_mean=0.0, reward_bound=0.0\n",
      "62: loss=1.047, reward_mean=0.1, reward_bound=0.0\n",
      "63: loss=0.891, reward_mean=0.1, reward_bound=0.0\n",
      "64: loss=1.094, reward_mean=0.0, reward_bound=0.0\n",
      "65: loss=0.732, reward_mean=0.0, reward_bound=0.0\n",
      "66: loss=0.847, reward_mean=0.1, reward_bound=0.0\n",
      "67: loss=0.890, reward_mean=0.0, reward_bound=0.0\n",
      "68: loss=1.014, reward_mean=0.0, reward_bound=0.0\n",
      "69: loss=0.723, reward_mean=0.0, reward_bound=0.0\n",
      "70: loss=0.989, reward_mean=0.0, reward_bound=0.0\n",
      "71: loss=0.834, reward_mean=0.1, reward_bound=0.0\n",
      "72: loss=0.876, reward_mean=0.0, reward_bound=0.0\n",
      "73: loss=0.871, reward_mean=0.1, reward_bound=0.0\n",
      "74: loss=0.866, reward_mean=0.0, reward_bound=0.0\n",
      "75: loss=0.813, reward_mean=0.0, reward_bound=0.0\n",
      "76: loss=0.824, reward_mean=0.1, reward_bound=0.0\n",
      "77: loss=0.727, reward_mean=0.0, reward_bound=0.0\n",
      "78: loss=0.844, reward_mean=0.0, reward_bound=0.0\n",
      "79: loss=0.713, reward_mean=0.1, reward_bound=0.0\n",
      "80: loss=0.878, reward_mean=0.0, reward_bound=0.0\n",
      "81: loss=0.763, reward_mean=0.0, reward_bound=0.0\n",
      "82: loss=0.736, reward_mean=0.0, reward_bound=0.0\n",
      "83: loss=0.764, reward_mean=0.0, reward_bound=0.0\n",
      "84: loss=0.631, reward_mean=0.0, reward_bound=0.0\n",
      "85: loss=0.509, reward_mean=0.1, reward_bound=0.0\n",
      "86: loss=0.715, reward_mean=0.0, reward_bound=0.0\n",
      "87: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "88: loss=0.573, reward_mean=0.0, reward_bound=0.0\n",
      "89: loss=0.800, reward_mean=0.0, reward_bound=0.0\n",
      "90: loss=0.621, reward_mean=0.0, reward_bound=0.0\n",
      "91: loss=0.658, reward_mean=0.1, reward_bound=0.0\n",
      "92: loss=0.504, reward_mean=0.0, reward_bound=0.0\n",
      "93: loss=0.433, reward_mean=0.0, reward_bound=0.0\n",
      "94: loss=0.540, reward_mean=0.0, reward_bound=0.0\n",
      "95: loss=0.423, reward_mean=0.0, reward_bound=0.0\n",
      "96: loss=0.579, reward_mean=0.1, reward_bound=0.0\n",
      "97: loss=0.359, reward_mean=0.1, reward_bound=0.0\n",
      "98: loss=0.376, reward_mean=0.0, reward_bound=0.0\n",
      "99: loss=0.220, reward_mean=0.0, reward_bound=0.0\n",
      "100: loss=0.281, reward_mean=0.1, reward_bound=0.0\n",
      "101: loss=0.407, reward_mean=0.1, reward_bound=0.0\n",
      "102: loss=0.314, reward_mean=0.1, reward_bound=0.0\n",
      "103: loss=0.285, reward_mean=0.0, reward_bound=0.0\n",
      "104: loss=0.227, reward_mean=0.0, reward_bound=0.0\n",
      "105: loss=0.202, reward_mean=0.1, reward_bound=0.0\n",
      "106: loss=0.163, reward_mean=0.0, reward_bound=0.0\n",
      "107: loss=0.236, reward_mean=0.0, reward_bound=0.0\n",
      "108: loss=0.105, reward_mean=0.0, reward_bound=0.0\n",
      "109: loss=0.113, reward_mean=0.1, reward_bound=0.0\n",
      "110: loss=0.284, reward_mean=0.1, reward_bound=0.0\n",
      "111: loss=0.211, reward_mean=0.1, reward_bound=0.0\n",
      "112: loss=0.065, reward_mean=0.1, reward_bound=0.0\n",
      "113: loss=0.030, reward_mean=0.0, reward_bound=0.0\n",
      "114: loss=0.160, reward_mean=0.0, reward_bound=0.0\n",
      "115: loss=0.023, reward_mean=0.0, reward_bound=0.0\n",
      "116: loss=0.138, reward_mean=0.0, reward_bound=0.0\n",
      "117: loss=0.133, reward_mean=0.1, reward_bound=0.0\n",
      "118: loss=0.113, reward_mean=0.0, reward_bound=0.0\n",
      "119: loss=0.106, reward_mean=0.1, reward_bound=0.0\n",
      "120: loss=0.134, reward_mean=0.1, reward_bound=0.0\n",
      "121: loss=0.074, reward_mean=0.1, reward_bound=0.0\n",
      "122: loss=0.108, reward_mean=0.0, reward_bound=0.0\n",
      "123: loss=0.080, reward_mean=0.0, reward_bound=0.0\n",
      "124: loss=0.125, reward_mean=0.1, reward_bound=0.0\n",
      "125: loss=0.176, reward_mean=0.1, reward_bound=0.0\n",
      "126: loss=0.110, reward_mean=0.1, reward_bound=0.0\n",
      "127: loss=0.085, reward_mean=0.0, reward_bound=0.0\n",
      "128: loss=0.064, reward_mean=0.0, reward_bound=0.0\n",
      "129: loss=0.139, reward_mean=0.1, reward_bound=0.0\n",
      "130: loss=0.051, reward_mean=0.0, reward_bound=0.0\n",
      "131: loss=0.121, reward_mean=0.0, reward_bound=0.0\n",
      "132: loss=0.057, reward_mean=0.1, reward_bound=0.0\n",
      "133: loss=0.023, reward_mean=0.1, reward_bound=0.0\n",
      "134: loss=0.076, reward_mean=0.0, reward_bound=0.0\n",
      "135: loss=0.042, reward_mean=0.0, reward_bound=0.0\n",
      "136: loss=0.040, reward_mean=0.1, reward_bound=0.0\n",
      "137: loss=0.013, reward_mean=0.0, reward_bound=0.0\n",
      "138: loss=0.012, reward_mean=0.1, reward_bound=0.0\n",
      "139: loss=0.007, reward_mean=0.1, reward_bound=0.0\n",
      "140: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "141: loss=0.110, reward_mean=0.1, reward_bound=0.0\n",
      "142: loss=0.007, reward_mean=0.1, reward_bound=0.0\n",
      "143: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "144: loss=0.044, reward_mean=0.1, reward_bound=0.0\n",
      "145: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "146: loss=0.003, reward_mean=0.0, reward_bound=0.0\n",
      "147: loss=0.005, reward_mean=0.0, reward_bound=0.0\n",
      "148: loss=0.003, reward_mean=0.0, reward_bound=0.0\n",
      "149: loss=0.043, reward_mean=0.2, reward_bound=0.0\n",
      "150: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "151: loss=0.003, reward_mean=0.0, reward_bound=0.0\n",
      "152: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "153: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "154: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "155: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "156: loss=0.003, reward_mean=0.0, reward_bound=0.0\n",
      "157: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "158: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "159: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "160: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "161: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "162: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "163: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "164: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "165: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "166: loss=0.057, reward_mean=0.1, reward_bound=0.0\n",
      "167: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "168: loss=0.001, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "170: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "171: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "172: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "173: loss=0.078, reward_mean=0.1, reward_bound=0.0\n",
      "174: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "175: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "176: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "177: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "178: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "179: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "180: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "181: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "182: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "183: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "184: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "185: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "186: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "187: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "188: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "189: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "190: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "191: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "192: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "193: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "194: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "195: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "196: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "197: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "198: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "199: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "200: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "201: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "202: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "203: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "204: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "205: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "206: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "207: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "208: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "209: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "210: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "211: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "212: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "213: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "214: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "215: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "216: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "217: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "218: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "219: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "220: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "221: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "222: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "223: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "224: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "225: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "226: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "227: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "228: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "229: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "230: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "231: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "232: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "233: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "234: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "235: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "236: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "237: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "238: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "239: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "240: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "241: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "242: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "243: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "244: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "245: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "246: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "247: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "248: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "249: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "250: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "251: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "252: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "253: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "254: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "255: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "256: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "257: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "258: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "259: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "260: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "261: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "262: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "263: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "264: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "265: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "266: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "267: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "268: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "269: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "270: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "271: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "272: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "273: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "274: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "275: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "276: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "277: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "278: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "279: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "280: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "281: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "282: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "283: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "284: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "285: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "286: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "287: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "288: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "289: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "290: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "291: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "292: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "293: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "294: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "295: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "296: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "297: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "298: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "299: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "300: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "301: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "302: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "303: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "304: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "305: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "306: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "307: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "308: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "309: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "310: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "311: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "312: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "313: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "314: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "315: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "316: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "317: loss=0.131, reward_mean=0.0, reward_bound=0.0\n",
      "318: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "319: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "320: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "321: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "322: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "323: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "324: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "325: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "326: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "327: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "328: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "329: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "330: loss=0.000, reward_mean=0.1, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "332: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "333: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "334: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "335: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "336: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "337: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "338: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "339: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "340: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "341: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "342: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "343: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "344: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "345: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "346: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "347: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "348: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "349: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "350: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "351: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "352: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "353: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "354: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "355: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "356: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "357: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "358: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "359: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "360: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "361: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "362: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "363: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "364: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "365: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "366: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "367: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "368: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "369: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "370: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "371: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "372: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "373: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "374: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "375: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "376: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "377: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "378: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "379: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "380: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "381: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "382: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "383: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "384: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "385: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "386: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "387: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "388: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "389: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "390: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "391: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "392: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "393: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "394: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "395: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "396: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "397: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "398: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "399: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "400: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "401: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "402: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "403: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "404: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "405: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "406: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "407: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "408: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "409: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "410: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "411: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "412: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "413: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "414: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "415: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "416: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "417: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "418: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "419: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "420: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "421: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "422: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "423: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "424: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "425: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "426: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "427: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "428: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "429: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "430: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "431: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "432: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "433: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "434: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "435: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "436: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "437: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "438: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "439: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "440: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "441: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "442: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "443: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "444: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "445: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "446: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "447: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "448: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "449: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "450: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "451: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "452: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "453: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "454: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "455: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "456: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "457: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "458: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "459: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "460: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "461: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "462: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "463: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "464: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "465: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "466: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "467: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "468: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "469: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "470: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "471: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "472: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "473: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "474: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "475: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "476: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "477: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "478: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "479: loss=0.138, reward_mean=0.0, reward_bound=0.0\n",
      "480: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "481: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "482: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "483: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "484: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "485: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "486: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "487: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "488: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "489: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "490: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "491: loss=0.000, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492: loss=0.094, reward_mean=0.0, reward_bound=0.0\n",
      "493: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "494: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "495: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "496: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "497: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "498: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "499: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "500: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "501: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "502: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "503: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "504: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "505: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "506: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "507: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "508: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "509: loss=0.066, reward_mean=0.0, reward_bound=0.0\n",
      "510: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "511: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "512: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "513: loss=0.080, reward_mean=0.1, reward_bound=0.0\n",
      "514: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "515: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "516: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "517: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "518: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "519: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "520: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "521: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "522: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "523: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "524: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "525: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "526: loss=0.095, reward_mean=0.1, reward_bound=0.0\n",
      "527: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "528: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "529: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "530: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "531: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "532: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "533: loss=0.049, reward_mean=0.0, reward_bound=0.0\n",
      "534: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "535: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "536: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "537: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "538: loss=0.054, reward_mean=0.1, reward_bound=0.0\n",
      "539: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "540: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "541: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "542: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "543: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "544: loss=0.002, reward_mean=0.2, reward_bound=0.0\n",
      "545: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "546: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "547: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "548: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "549: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "550: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "551: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "552: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "553: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "554: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "555: loss=0.095, reward_mean=0.1, reward_bound=0.0\n",
      "556: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "557: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "558: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "559: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "560: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "561: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "562: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "563: loss=0.068, reward_mean=0.1, reward_bound=0.0\n",
      "564: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "565: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "566: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "567: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "568: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "569: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "570: loss=0.047, reward_mean=0.1, reward_bound=0.0\n",
      "571: loss=0.003, reward_mean=0.3, reward_bound=0.5\n",
      "572: loss=0.040, reward_mean=0.2, reward_bound=0.0\n",
      "573: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "574: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "575: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "576: loss=0.050, reward_mean=0.1, reward_bound=0.0\n",
      "577: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "578: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "579: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "580: loss=0.029, reward_mean=0.0, reward_bound=0.0\n",
      "581: loss=0.031, reward_mean=0.0, reward_bound=0.0\n",
      "582: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "583: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "584: loss=0.029, reward_mean=0.1, reward_bound=0.0\n",
      "585: loss=0.016, reward_mean=0.1, reward_bound=0.0\n",
      "586: loss=0.014, reward_mean=0.1, reward_bound=0.0\n",
      "587: loss=0.028, reward_mean=0.0, reward_bound=0.0\n",
      "588: loss=0.046, reward_mean=0.1, reward_bound=0.0\n",
      "589: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "590: loss=0.034, reward_mean=0.1, reward_bound=0.0\n",
      "591: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "592: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "593: loss=0.010, reward_mean=0.1, reward_bound=0.0\n",
      "594: loss=0.025, reward_mean=0.1, reward_bound=0.0\n",
      "595: loss=0.066, reward_mean=0.0, reward_bound=0.0\n",
      "596: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "597: loss=0.021, reward_mean=0.1, reward_bound=0.0\n",
      "598: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "599: loss=0.022, reward_mean=0.0, reward_bound=0.0\n",
      "600: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "601: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "602: loss=0.029, reward_mean=0.1, reward_bound=0.0\n",
      "603: loss=0.141, reward_mean=0.0, reward_bound=0.0\n",
      "604: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "605: loss=0.006, reward_mean=0.0, reward_bound=0.0\n",
      "606: loss=0.046, reward_mean=0.2, reward_bound=0.0\n",
      "607: loss=0.011, reward_mean=0.1, reward_bound=0.0\n",
      "608: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "609: loss=0.052, reward_mean=0.0, reward_bound=0.0\n",
      "610: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "611: loss=0.032, reward_mean=0.1, reward_bound=0.0\n",
      "612: loss=0.107, reward_mean=0.1, reward_bound=0.0\n",
      "613: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "614: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "615: loss=0.066, reward_mean=0.1, reward_bound=0.0\n",
      "616: loss=0.132, reward_mean=0.0, reward_bound=0.0\n",
      "617: loss=0.007, reward_mean=0.1, reward_bound=0.0\n",
      "618: loss=0.027, reward_mean=0.1, reward_bound=0.0\n",
      "619: loss=0.074, reward_mean=0.1, reward_bound=0.0\n",
      "620: loss=0.025, reward_mean=0.1, reward_bound=0.0\n",
      "621: loss=0.008, reward_mean=0.1, reward_bound=0.0\n",
      "622: loss=0.076, reward_mean=0.0, reward_bound=0.0\n",
      "623: loss=0.028, reward_mean=0.1, reward_bound=0.0\n",
      "624: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "625: loss=0.051, reward_mean=0.1, reward_bound=0.0\n",
      "626: loss=0.084, reward_mean=0.0, reward_bound=0.0\n",
      "627: loss=0.175, reward_mean=0.1, reward_bound=0.0\n",
      "628: loss=0.089, reward_mean=0.1, reward_bound=0.0\n",
      "629: loss=0.081, reward_mean=0.0, reward_bound=0.0\n",
      "630: loss=0.047, reward_mean=0.0, reward_bound=0.0\n",
      "631: loss=0.007, reward_mean=0.0, reward_bound=0.0\n",
      "632: loss=0.035, reward_mean=0.1, reward_bound=0.0\n",
      "633: loss=0.249, reward_mean=0.0, reward_bound=0.0\n",
      "634: loss=0.052, reward_mean=0.0, reward_bound=0.0\n",
      "635: loss=0.213, reward_mean=0.0, reward_bound=0.0\n",
      "636: loss=0.134, reward_mean=0.0, reward_bound=0.0\n",
      "637: loss=0.101, reward_mean=0.0, reward_bound=0.0\n",
      "638: loss=0.124, reward_mean=0.0, reward_bound=0.0\n",
      "639: loss=0.124, reward_mean=0.1, reward_bound=0.0\n",
      "640: loss=0.081, reward_mean=0.1, reward_bound=0.0\n",
      "641: loss=0.160, reward_mean=0.0, reward_bound=0.0\n",
      "642: loss=0.273, reward_mean=0.0, reward_bound=0.0\n",
      "643: loss=0.169, reward_mean=0.1, reward_bound=0.0\n",
      "644: loss=0.150, reward_mean=0.0, reward_bound=0.0\n",
      "645: loss=0.071, reward_mean=0.0, reward_bound=0.0\n",
      "646: loss=0.154, reward_mean=0.1, reward_bound=0.0\n",
      "647: loss=0.145, reward_mean=0.0, reward_bound=0.0\n",
      "648: loss=0.035, reward_mean=0.1, reward_bound=0.0\n",
      "649: loss=0.041, reward_mean=0.0, reward_bound=0.0\n",
      "650: loss=0.093, reward_mean=0.0, reward_bound=0.0\n",
      "651: loss=0.077, reward_mean=0.0, reward_bound=0.0\n",
      "652: loss=0.190, reward_mean=0.0, reward_bound=0.0\n",
      "653: loss=0.174, reward_mean=0.1, reward_bound=0.0\n",
      "654: loss=0.112, reward_mean=0.0, reward_bound=0.0\n",
      "655: loss=0.124, reward_mean=0.0, reward_bound=0.0\n",
      "656: loss=0.219, reward_mean=0.1, reward_bound=0.0\n",
      "657: loss=0.061, reward_mean=0.1, reward_bound=0.0\n",
      "658: loss=0.046, reward_mean=0.1, reward_bound=0.0\n",
      "659: loss=0.041, reward_mean=0.1, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660: loss=0.007, reward_mean=0.0, reward_bound=0.0\n",
      "661: loss=0.072, reward_mean=0.0, reward_bound=0.0\n",
      "662: loss=0.091, reward_mean=0.1, reward_bound=0.0\n",
      "663: loss=0.061, reward_mean=0.1, reward_bound=0.0\n",
      "664: loss=0.004, reward_mean=0.0, reward_bound=0.0\n",
      "665: loss=0.053, reward_mean=0.0, reward_bound=0.0\n",
      "666: loss=0.084, reward_mean=0.1, reward_bound=0.0\n",
      "667: loss=0.181, reward_mean=0.1, reward_bound=0.0\n",
      "668: loss=0.011, reward_mean=0.0, reward_bound=0.0\n",
      "669: loss=0.033, reward_mean=0.1, reward_bound=0.0\n",
      "670: loss=0.017, reward_mean=0.1, reward_bound=0.0\n",
      "671: loss=0.042, reward_mean=0.0, reward_bound=0.0\n",
      "672: loss=0.027, reward_mean=0.1, reward_bound=0.0\n",
      "673: loss=0.078, reward_mean=0.1, reward_bound=0.0\n",
      "674: loss=0.026, reward_mean=0.1, reward_bound=0.0\n",
      "675: loss=0.049, reward_mean=0.1, reward_bound=0.0\n",
      "676: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "677: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "678: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "679: loss=0.007, reward_mean=0.0, reward_bound=0.0\n",
      "680: loss=0.046, reward_mean=0.1, reward_bound=0.0\n",
      "681: loss=0.036, reward_mean=0.1, reward_bound=0.0\n",
      "682: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "683: loss=0.041, reward_mean=0.1, reward_bound=0.0\n",
      "684: loss=0.042, reward_mean=0.1, reward_bound=0.0\n",
      "685: loss=0.076, reward_mean=0.0, reward_bound=0.0\n",
      "686: loss=0.048, reward_mean=0.1, reward_bound=0.0\n",
      "687: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "688: loss=0.034, reward_mean=0.1, reward_bound=0.0\n",
      "689: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "690: loss=0.015, reward_mean=0.0, reward_bound=0.0\n",
      "691: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "692: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "693: loss=0.055, reward_mean=0.1, reward_bound=0.0\n",
      "694: loss=0.011, reward_mean=0.1, reward_bound=0.0\n",
      "695: loss=0.040, reward_mean=0.1, reward_bound=0.0\n",
      "696: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "697: loss=0.009, reward_mean=0.1, reward_bound=0.0\n",
      "698: loss=0.089, reward_mean=0.1, reward_bound=0.0\n",
      "699: loss=0.008, reward_mean=0.0, reward_bound=0.0\n",
      "700: loss=0.012, reward_mean=0.0, reward_bound=0.0\n",
      "701: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "702: loss=0.028, reward_mean=0.1, reward_bound=0.0\n",
      "703: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "704: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "705: loss=0.057, reward_mean=0.1, reward_bound=0.0\n",
      "706: loss=0.023, reward_mean=0.0, reward_bound=0.0\n",
      "707: loss=0.061, reward_mean=0.1, reward_bound=0.0\n",
      "708: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "709: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "710: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "711: loss=0.064, reward_mean=0.1, reward_bound=0.0\n",
      "712: loss=0.011, reward_mean=0.0, reward_bound=0.0\n",
      "713: loss=0.013, reward_mean=0.1, reward_bound=0.0\n",
      "714: loss=0.025, reward_mean=0.0, reward_bound=0.0\n",
      "715: loss=0.004, reward_mean=0.0, reward_bound=0.0\n",
      "716: loss=0.023, reward_mean=0.1, reward_bound=0.0\n",
      "717: loss=0.080, reward_mean=0.1, reward_bound=0.0\n",
      "718: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "719: loss=0.007, reward_mean=0.1, reward_bound=0.0\n",
      "720: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "721: loss=0.012, reward_mean=0.0, reward_bound=0.0\n",
      "722: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "723: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "724: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "725: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "726: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "727: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "728: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "729: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "730: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "731: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "732: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "733: loss=0.003, reward_mean=0.0, reward_bound=0.0\n",
      "734: loss=0.007, reward_mean=0.1, reward_bound=0.0\n",
      "735: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "736: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "737: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "738: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "739: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "740: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "741: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "742: loss=0.037, reward_mean=0.1, reward_bound=0.0\n",
      "743: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "744: loss=0.036, reward_mean=0.1, reward_bound=0.0\n",
      "745: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "746: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "747: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "748: loss=0.053, reward_mean=0.1, reward_bound=0.0\n",
      "749: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "750: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "751: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "752: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "753: loss=0.082, reward_mean=0.1, reward_bound=0.0\n",
      "754: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "755: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "756: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "757: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "758: loss=0.037, reward_mean=0.1, reward_bound=0.0\n",
      "759: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "760: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "761: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "762: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "763: loss=0.025, reward_mean=0.1, reward_bound=0.0\n",
      "764: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "765: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "766: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "767: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "768: loss=0.007, reward_mean=0.1, reward_bound=0.0\n",
      "769: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "770: loss=0.004, reward_mean=0.0, reward_bound=0.0\n",
      "771: loss=0.085, reward_mean=0.0, reward_bound=0.0\n",
      "772: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "773: loss=0.006, reward_mean=0.0, reward_bound=0.0\n",
      "774: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "775: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "776: loss=0.039, reward_mean=0.1, reward_bound=0.0\n",
      "777: loss=0.011, reward_mean=0.1, reward_bound=0.0\n",
      "778: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "779: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "780: loss=0.026, reward_mean=0.1, reward_bound=0.0\n",
      "781: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "782: loss=0.031, reward_mean=0.1, reward_bound=0.0\n",
      "783: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "784: loss=0.004, reward_mean=0.0, reward_bound=0.0\n",
      "785: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "786: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "787: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "788: loss=0.027, reward_mean=0.1, reward_bound=0.0\n",
      "789: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "790: loss=0.008, reward_mean=0.1, reward_bound=0.0\n",
      "791: loss=0.031, reward_mean=0.1, reward_bound=0.0\n",
      "792: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "793: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "794: loss=0.031, reward_mean=0.1, reward_bound=0.0\n",
      "795: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "796: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "797: loss=0.115, reward_mean=0.1, reward_bound=0.0\n",
      "798: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "799: loss=0.029, reward_mean=0.1, reward_bound=0.0\n",
      "800: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "801: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "802: loss=0.065, reward_mean=0.0, reward_bound=0.0\n",
      "803: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "804: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "805: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "806: loss=0.058, reward_mean=0.1, reward_bound=0.0\n",
      "807: loss=0.014, reward_mean=0.0, reward_bound=0.0\n",
      "808: loss=0.017, reward_mean=0.1, reward_bound=0.0\n",
      "809: loss=0.010, reward_mean=0.1, reward_bound=0.0\n",
      "810: loss=0.043, reward_mean=0.1, reward_bound=0.0\n",
      "811: loss=0.032, reward_mean=0.1, reward_bound=0.0\n",
      "812: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "813: loss=0.033, reward_mean=0.1, reward_bound=0.0\n",
      "814: loss=0.079, reward_mean=0.1, reward_bound=0.0\n",
      "815: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "816: loss=0.026, reward_mean=0.1, reward_bound=0.0\n",
      "817: loss=0.018, reward_mean=0.1, reward_bound=0.0\n",
      "818: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "819: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "820: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "821: loss=0.004, reward_mean=0.0, reward_bound=0.0\n",
      "822: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "823: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "824: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "825: loss=0.036, reward_mean=0.1, reward_bound=0.0\n",
      "826: loss=0.006, reward_mean=0.1, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "828: loss=0.007, reward_mean=0.1, reward_bound=0.0\n",
      "829: loss=0.066, reward_mean=0.1, reward_bound=0.0\n",
      "830: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "831: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "832: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "833: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "834: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "835: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "836: loss=0.029, reward_mean=0.1, reward_bound=0.0\n",
      "837: loss=0.006, reward_mean=0.1, reward_bound=0.0\n",
      "838: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "839: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "840: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "841: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "842: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "843: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "844: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "845: loss=0.004, reward_mean=0.0, reward_bound=0.0\n",
      "846: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "847: loss=0.005, reward_mean=0.1, reward_bound=0.0\n",
      "848: loss=0.036, reward_mean=0.1, reward_bound=0.0\n",
      "849: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "850: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "851: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "852: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "853: loss=0.003, reward_mean=0.1, reward_bound=0.0\n",
      "854: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "855: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "856: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "857: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "858: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "859: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "860: loss=0.043, reward_mean=0.2, reward_bound=0.0\n",
      "861: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "862: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "863: loss=0.038, reward_mean=0.1, reward_bound=0.0\n",
      "864: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "865: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "866: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "867: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "868: loss=0.068, reward_mean=0.1, reward_bound=0.0\n",
      "869: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "870: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "871: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "872: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "873: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "874: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "875: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "876: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "877: loss=0.004, reward_mean=0.1, reward_bound=0.0\n",
      "878: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "879: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "880: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "881: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "882: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "883: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "884: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "885: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "886: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "887: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "888: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "889: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "890: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "891: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "892: loss=0.052, reward_mean=0.1, reward_bound=0.0\n",
      "893: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "894: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "895: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "896: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "897: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "898: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "899: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "900: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "901: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "902: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "903: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "904: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "905: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "906: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "907: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "908: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "909: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "910: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "911: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "912: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "913: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "914: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "915: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "916: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "917: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "918: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "919: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "920: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "921: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "922: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "923: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "924: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "925: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "926: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "927: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "928: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "929: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "930: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "931: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "932: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "933: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "934: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "935: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "936: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "937: loss=0.053, reward_mean=0.1, reward_bound=0.0\n",
      "938: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "939: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "940: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "941: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "942: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "943: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "944: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "945: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "946: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "947: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "948: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "949: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "950: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "951: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "952: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "953: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "954: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "955: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "956: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "957: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "958: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "959: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "960: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "961: loss=0.002, reward_mean=0.0, reward_bound=0.0\n",
      "962: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "963: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "964: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "965: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "966: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "967: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "968: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "969: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "970: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "971: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "972: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "973: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "974: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "975: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "976: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "977: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "978: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "979: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "980: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "981: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "982: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "983: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "984: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "985: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "986: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "987: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "988: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "989: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "990: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "991: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "992: loss=0.000, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "994: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "995: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "996: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "997: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "998: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "999: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1000: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1001: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1002: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1003: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1004: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1005: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1006: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1007: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1008: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1009: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1010: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1011: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1012: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1013: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1014: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1015: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1016: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1017: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1018: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1019: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1020: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1021: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1022: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1023: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1024: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1025: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1026: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1027: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1028: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1029: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1030: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1031: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1032: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1033: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1034: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1035: loss=0.071, reward_mean=0.1, reward_bound=0.0\n",
      "1036: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1037: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1038: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1039: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "1040: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1041: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1042: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1043: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1044: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1045: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1046: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1047: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1048: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1049: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "1050: loss=0.049, reward_mean=0.2, reward_bound=0.0\n",
      "1051: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1052: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1053: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1054: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1055: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1056: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1057: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1058: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1059: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "1060: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1061: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1062: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1063: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1064: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1065: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1066: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1067: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1068: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1069: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1070: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1071: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1072: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1073: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1074: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1075: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1076: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1077: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "1078: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "1079: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "1080: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1081: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1082: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1083: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1084: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1085: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1086: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1087: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1088: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1089: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1090: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "1091: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1092: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1093: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1094: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1095: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1096: loss=0.056, reward_mean=0.0, reward_bound=0.0\n",
      "1097: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1098: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1099: loss=0.041, reward_mean=0.1, reward_bound=0.0\n",
      "1100: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1101: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1102: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1103: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1104: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1105: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1106: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1107: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1108: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "1109: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1110: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1111: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1112: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1113: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1114: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1115: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1116: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1117: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1118: loss=0.002, reward_mean=0.2, reward_bound=0.0\n",
      "1119: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "1120: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1121: loss=0.052, reward_mean=0.2, reward_bound=0.0\n",
      "1122: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1123: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1124: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1125: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1126: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1127: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1128: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1129: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1130: loss=0.002, reward_mean=0.1, reward_bound=0.0\n",
      "1131: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1132: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1133: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1134: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1135: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1136: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1137: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1138: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1139: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1140: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1141: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1142: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "1143: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1144: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1145: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1146: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1147: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1148: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1149: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1150: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1151: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1152: loss=0.000, reward_mean=0.1, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1154: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "1155: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1156: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1157: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1158: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1159: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1160: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1161: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1162: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1163: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1164: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1165: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1166: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1167: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1168: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1169: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "1170: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1171: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1172: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1173: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1174: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1175: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1176: loss=0.001, reward_mean=0.1, reward_bound=0.0\n",
      "1177: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1178: loss=0.001, reward_mean=0.2, reward_bound=0.0\n",
      "1179: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1180: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1181: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "1182: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1183: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1184: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1185: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1186: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1187: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "1188: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1189: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1190: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1191: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1192: loss=0.001, reward_mean=0.0, reward_bound=0.0\n",
      "1193: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1194: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1195: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1196: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1197: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1198: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1199: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1200: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1201: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1202: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1203: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1204: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1205: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1206: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1207: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1208: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1209: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1210: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1211: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1212: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1213: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1214: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1215: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1216: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1217: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1218: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1219: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1220: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1221: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1222: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1223: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1224: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1225: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1226: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1227: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1228: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1229: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1230: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1231: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1232: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1233: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1234: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1235: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1236: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1237: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1238: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "1239: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1240: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1241: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1242: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1243: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1244: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1245: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1246: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1247: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1248: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1249: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1250: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1251: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1252: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1253: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1254: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1255: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1256: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1257: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1258: loss=0.000, reward_mean=0.2, reward_bound=0.0\n",
      "1259: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1260: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1261: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1262: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1263: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1264: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1265: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1266: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1267: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1268: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1269: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1270: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1271: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1272: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1273: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1274: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1275: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1276: loss=0.000, reward_mean=0.1, reward_bound=0.0\n",
      "1277: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1278: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1279: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1280: loss=0.000, reward_mean=0.0, reward_bound=0.0\n",
      "1281: loss=0.000, reward_mean=0.1, reward_bound=0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-53c095376cd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#action score will put to target function to calculate the difference between network output and agent chosen action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#so the agent will choose the action will higher network output value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0miter_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterate_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mobs_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macts_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPERCENTILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-678b9d2fd350>\u001b[0m in \u001b[0;36miterate_batches\u001b[1;34m(env, net, batch_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mobs_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mact_probs_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m#we use tensor.data to uncompress tensor and convert to Numpy array, this has same 2 dimension as input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#we want to get the first batch from the batch array, therefore we use [0], which is action probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f5cab74108d0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #we create all necessary objects: environment, network, target function, optimizer and TensorBoard writer\n",
    "    env = DiscreteOneHotWrapper(gym.make(\"FrozenLake-v1\"))\n",
    "    #The line below will create a monitor to save the agent action as video\n",
    "    env = gym.wrappers.Monitor(env, directory=\"mon2\", force=True)\n",
    "    obs_size = env.observation_space.shape[0]\n",
    "    n_actions = env.action_space.n\n",
    "    \n",
    "    net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "    objective = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "    writer = SummaryWriter(comment=\"-frozenlake-naive\")\n",
    "    \n",
    "    #we get the batch in loop, filter the batch, get observation and action vector, reward boundary and mean\n",
    "    #we make the gradient zero and give the observation to network and get the action score\n",
    "    #action score will put to target function to calculate the difference between network output and agent chosen action\n",
    "    #so the agent will choose the action will higher network output value\n",
    "    for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "        obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
    "        optimizer.zero_grad()\n",
    "        action_scores_v = net(obs_v)\n",
    "        loss_v = objective(action_scores_v, acts_v)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #For monitoring, show iterate number, loss, batch reward mean, reward boundary, all these values will be \n",
    "        #written in TensorBoard\n",
    "        print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" %(iter_no, loss_v.item(), reward_m, reward_b))\n",
    "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "        writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
    "        writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
    "        \n",
    "        #if mean reward > 199, we stop training, it is because in Gym, when 100 episodes > 195,\n",
    "        #the cartpole problem is said to be successfully solved, it can balance infinitely long,\n",
    "        #but in CartPole environment, it used TimeLimit to limit the episodes within 200, so it is forced to stop after\n",
    "        #200 steps. Therefore we use > 199 steps as to indicate the problem solved\n",
    "        if reward_m > 199:\n",
    "            print(\"Solved!\")\n",
    "            break\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement",
   "language": "python",
   "name": "reinforcement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
