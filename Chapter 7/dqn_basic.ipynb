{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06b99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from lib import dqn_model, common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ad9553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879: done 1 games, mean reward -21.000, speed 195.16 f/s, eps 0.99\n",
      "1639: done 2 games, mean reward -21.000, speed 225.75 f/s, eps 0.98\n",
      "2617: done 3 games, mean reward -20.667, speed 214.22 f/s, eps 0.97\n",
      "3528: done 4 games, mean reward -20.500, speed 172.31 f/s, eps 0.96\n",
      "4429: done 5 games, mean reward -20.400, speed 146.31 f/s, eps 0.96\n",
      "5268: done 6 games, mean reward -20.500, speed 132.00 f/s, eps 0.95\n",
      "6181: done 7 games, mean reward -20.571, speed 156.99 f/s, eps 0.94\n",
      "7226: done 8 games, mean reward -20.500, speed 159.40 f/s, eps 0.93\n",
      "8057: done 9 games, mean reward -20.444, speed 159.57 f/s, eps 0.92\n",
      "9173: done 10 games, mean reward -20.300, speed 158.30 f/s, eps 0.91\n",
      "9931: done 11 games, mean reward -20.364, speed 161.55 f/s, eps 0.90\n",
      "10892: done 12 games, mean reward -20.333, speed 58.79 f/s, eps 0.89\n",
      "11711: done 13 games, mean reward -20.385, speed 55.28 f/s, eps 0.88\n",
      "12701: done 14 games, mean reward -20.286, speed 54.79 f/s, eps 0.87\n",
      "13591: done 15 games, mean reward -20.333, speed 51.38 f/s, eps 0.86\n",
      "14396: done 16 games, mean reward -20.375, speed 52.35 f/s, eps 0.86\n",
      "15155: done 17 games, mean reward -20.412, speed 50.07 f/s, eps 0.85\n",
      "15977: done 18 games, mean reward -20.444, speed 48.28 f/s, eps 0.84\n",
      "16888: done 19 games, mean reward -20.368, speed 50.63 f/s, eps 0.83\n",
      "17862: done 20 games, mean reward -20.350, speed 48.71 f/s, eps 0.82\n",
      "18781: done 21 games, mean reward -20.333, speed 49.95 f/s, eps 0.81\n",
      "19874: done 22 games, mean reward -20.273, speed 52.24 f/s, eps 0.80\n",
      "20714: done 23 games, mean reward -20.261, speed 51.41 f/s, eps 0.79\n",
      "21561: done 24 games, mean reward -20.292, speed 50.65 f/s, eps 0.78\n",
      "22486: done 25 games, mean reward -20.320, speed 49.20 f/s, eps 0.78\n",
      "23379: done 26 games, mean reward -20.308, speed 48.77 f/s, eps 0.77\n",
      "24560: done 27 games, mean reward -20.222, speed 50.01 f/s, eps 0.75\n",
      "25496: done 28 games, mean reward -20.214, speed 50.45 f/s, eps 0.75\n",
      "26552: done 29 games, mean reward -20.172, speed 50.20 f/s, eps 0.73\n",
      "27494: done 30 games, mean reward -20.200, speed 45.01 f/s, eps 0.73\n",
      "28606: done 31 games, mean reward -20.161, speed 50.14 f/s, eps 0.71\n",
      "29523: done 32 games, mean reward -20.156, speed 50.64 f/s, eps 0.70\n",
      "30510: done 33 games, mean reward -20.121, speed 51.66 f/s, eps 0.69\n",
      "31350: done 34 games, mean reward -20.118, speed 48.43 f/s, eps 0.69\n",
      "32380: done 35 games, mean reward -20.114, speed 49.75 f/s, eps 0.68\n",
      "33562: done 36 games, mean reward -20.083, speed 55.22 f/s, eps 0.66\n",
      "34761: done 37 games, mean reward -20.081, speed 54.22 f/s, eps 0.65\n",
      "35748: done 38 games, mean reward -20.079, speed 55.61 f/s, eps 0.64\n",
      "36904: done 39 games, mean reward -20.051, speed 56.40 f/s, eps 0.63\n",
      "37805: done 40 games, mean reward -20.050, speed 52.37 f/s, eps 0.62\n",
      "38595: done 41 games, mean reward -20.073, speed 54.73 f/s, eps 0.61\n",
      "39500: done 42 games, mean reward -20.095, speed 53.17 f/s, eps 0.60\n",
      "40470: done 43 games, mean reward -20.116, speed 52.64 f/s, eps 0.60\n",
      "41350: done 44 games, mean reward -20.136, speed 54.72 f/s, eps 0.59\n",
      "42712: done 45 games, mean reward -20.111, speed 53.84 f/s, eps 0.57\n",
      "43698: done 46 games, mean reward -20.109, speed 51.35 f/s, eps 0.56\n",
      "44854: done 47 games, mean reward -20.106, speed 52.78 f/s, eps 0.55\n",
      "45746: done 48 games, mean reward -20.125, speed 51.00 f/s, eps 0.54\n",
      "46793: done 49 games, mean reward -20.143, speed 54.99 f/s, eps 0.53\n",
      "47877: done 50 games, mean reward -20.120, speed 57.95 f/s, eps 0.52\n",
      "48761: done 51 games, mean reward -20.118, speed 57.77 f/s, eps 0.51\n",
      "50036: done 52 games, mean reward -20.115, speed 58.37 f/s, eps 0.50\n",
      "51095: done 53 games, mean reward -20.132, speed 58.18 f/s, eps 0.49\n",
      "52231: done 54 games, mean reward -20.093, speed 58.39 f/s, eps 0.48\n",
      "53150: done 55 games, mean reward -20.091, speed 57.90 f/s, eps 0.47\n",
      "54471: done 56 games, mean reward -20.107, speed 57.88 f/s, eps 0.46\n",
      "55935: done 57 games, mean reward -20.070, speed 57.37 f/s, eps 0.44\n",
      "57303: done 58 games, mean reward -20.052, speed 58.26 f/s, eps 0.43\n",
      "58567: done 59 games, mean reward -20.034, speed 57.49 f/s, eps 0.41\n",
      "59608: done 60 games, mean reward -20.033, speed 58.07 f/s, eps 0.40\n",
      "60773: done 61 games, mean reward -20.016, speed 58.06 f/s, eps 0.39\n",
      "61795: done 62 games, mean reward -20.016, speed 57.99 f/s, eps 0.38\n",
      "63052: done 63 games, mean reward -20.016, speed 57.99 f/s, eps 0.37\n",
      "64746: done 64 games, mean reward -19.969, speed 58.10 f/s, eps 0.35\n",
      "66302: done 65 games, mean reward -19.985, speed 57.85 f/s, eps 0.34\n",
      "67533: done 66 games, mean reward -19.985, speed 56.86 f/s, eps 0.32\n",
      "68904: done 67 games, mean reward -19.985, speed 57.67 f/s, eps 0.31\n",
      "70409: done 68 games, mean reward -19.956, speed 58.15 f/s, eps 0.30\n",
      "72365: done 69 games, mean reward -19.942, speed 57.52 f/s, eps 0.28\n",
      "73726: done 70 games, mean reward -19.957, speed 58.00 f/s, eps 0.26\n",
      "75376: done 71 games, mean reward -19.958, speed 57.88 f/s, eps 0.25\n",
      "77090: done 72 games, mean reward -19.931, speed 57.63 f/s, eps 0.23\n",
      "79080: done 73 games, mean reward -19.863, speed 57.78 f/s, eps 0.21\n",
      "80807: done 74 games, mean reward -19.865, speed 57.97 f/s, eps 0.19\n",
      "82963: done 75 games, mean reward -19.773, speed 57.46 f/s, eps 0.17\n",
      "84536: done 76 games, mean reward -19.776, speed 57.62 f/s, eps 0.15\n",
      "86680: done 77 games, mean reward -19.714, speed 58.14 f/s, eps 0.13\n",
      "88720: done 78 games, mean reward -19.679, speed 57.50 f/s, eps 0.11\n",
      "90990: done 79 games, mean reward -19.658, speed 56.83 f/s, eps 0.09\n",
      "92892: done 80 games, mean reward -19.650, speed 58.00 f/s, eps 0.07\n",
      "95044: done 81 games, mean reward -19.617, speed 54.98 f/s, eps 0.05\n",
      "96814: done 82 games, mean reward -19.622, speed 55.74 f/s, eps 0.03\n",
      "99116: done 83 games, mean reward -19.566, speed 55.34 f/s, eps 0.02\n",
      "101609: done 84 games, mean reward -19.512, speed 57.04 f/s, eps 0.02\n",
      "103987: done 85 games, mean reward -19.471, speed 57.87 f/s, eps 0.02\n",
      "106128: done 86 games, mean reward -19.395, speed 57.34 f/s, eps 0.02\n",
      "108574: done 87 games, mean reward -19.368, speed 56.34 f/s, eps 0.02\n",
      "111075: done 88 games, mean reward -19.307, speed 58.01 f/s, eps 0.02\n",
      "114345: done 89 games, mean reward -19.247, speed 57.54 f/s, eps 0.02\n",
      "116437: done 90 games, mean reward -19.233, speed 58.14 f/s, eps 0.02\n",
      "118737: done 91 games, mean reward -19.187, speed 57.79 f/s, eps 0.02\n",
      "121664: done 92 games, mean reward -19.120, speed 58.01 f/s, eps 0.02\n",
      "124076: done 93 games, mean reward -19.108, speed 57.89 f/s, eps 0.02\n",
      "126436: done 94 games, mean reward -19.085, speed 57.98 f/s, eps 0.02\n",
      "129065: done 95 games, mean reward -19.063, speed 58.09 f/s, eps 0.02\n",
      "131742: done 96 games, mean reward -19.062, speed 57.86 f/s, eps 0.02\n",
      "134513: done 97 games, mean reward -19.052, speed 57.82 f/s, eps 0.02\n",
      "137667: done 98 games, mean reward -19.010, speed 57.95 f/s, eps 0.02\n",
      "140313: done 99 games, mean reward -18.960, speed 58.03 f/s, eps 0.02\n",
      "143521: done 100 games, mean reward -18.850, speed 57.36 f/s, eps 0.02\n",
      "146285: done 101 games, mean reward -18.830, speed 58.05 f/s, eps 0.02\n",
      "149193: done 102 games, mean reward -18.770, speed 58.11 f/s, eps 0.02\n",
      "151553: done 103 games, mean reward -18.750, speed 58.15 f/s, eps 0.02\n",
      "153996: done 104 games, mean reward -18.720, speed 58.11 f/s, eps 0.02\n",
      "155481: done 105 games, mean reward -18.700, speed 57.78 f/s, eps 0.02\n",
      "157968: done 106 games, mean reward -18.660, speed 57.65 f/s, eps 0.02\n",
      "160877: done 107 games, mean reward -18.630, speed 58.20 f/s, eps 0.02\n",
      "163939: done 108 games, mean reward -18.610, speed 57.54 f/s, eps 0.02\n",
      "167046: done 109 games, mean reward -18.520, speed 57.63 f/s, eps 0.02\n",
      "169695: done 110 games, mean reward -18.480, speed 57.81 f/s, eps 0.02\n",
      "172801: done 111 games, mean reward -18.400, speed 57.92 f/s, eps 0.02\n",
      "176023: done 112 games, mean reward -18.320, speed 57.71 f/s, eps 0.02\n",
      "179395: done 113 games, mean reward -18.230, speed 57.67 f/s, eps 0.02\n",
      "182715: done 114 games, mean reward -18.200, speed 57.94 f/s, eps 0.02\n",
      "185629: done 115 games, mean reward -18.130, speed 57.88 f/s, eps 0.02\n",
      "188753: done 116 games, mean reward -18.010, speed 58.10 f/s, eps 0.02\n",
      "191712: done 117 games, mean reward -17.940, speed 57.97 f/s, eps 0.02\n",
      "195003: done 118 games, mean reward -17.870, speed 57.84 f/s, eps 0.02\n",
      "197892: done 119 games, mean reward -17.790, speed 57.68 f/s, eps 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201248: done 120 games, mean reward -17.670, speed 57.54 f/s, eps 0.02\n",
      "203865: done 121 games, mean reward -17.620, speed 58.20 f/s, eps 0.02\n",
      "207024: done 122 games, mean reward -17.560, speed 58.09 f/s, eps 0.02\n",
      "210535: done 123 games, mean reward -17.430, speed 57.84 f/s, eps 0.02\n",
      "214118: done 124 games, mean reward -17.330, speed 58.06 f/s, eps 0.02\n",
      "218117: done 125 games, mean reward -17.170, speed 58.16 f/s, eps 0.02\n",
      "222786: done 126 games, mean reward -16.960, speed 57.91 f/s, eps 0.02\n",
      "226388: done 127 games, mean reward -16.900, speed 57.66 f/s, eps 0.02\n",
      "229692: done 128 games, mean reward -16.760, speed 57.91 f/s, eps 0.02\n",
      "233257: done 129 games, mean reward -16.680, speed 57.78 f/s, eps 0.02\n",
      "236592: done 130 games, mean reward -16.550, speed 58.13 f/s, eps 0.02\n",
      "240029: done 131 games, mean reward -16.350, speed 57.69 f/s, eps 0.02\n",
      "243533: done 132 games, mean reward -16.170, speed 58.21 f/s, eps 0.02\n",
      "246744: done 133 games, mean reward -15.940, speed 57.62 f/s, eps 0.02\n",
      "250098: done 134 games, mean reward -15.710, speed 57.80 f/s, eps 0.02\n",
      "253119: done 135 games, mean reward -15.440, speed 57.82 f/s, eps 0.02\n",
      "255963: done 136 games, mean reward -15.150, speed 58.16 f/s, eps 0.02\n",
      "258668: done 137 games, mean reward -14.840, speed 57.94 f/s, eps 0.02\n",
      "260806: done 138 games, mean reward -14.450, speed 58.28 f/s, eps 0.02\n",
      "264073: done 139 games, mean reward -14.170, speed 57.89 f/s, eps 0.02\n",
      "267393: done 140 games, mean reward -13.940, speed 58.22 f/s, eps 0.02\n",
      "269838: done 141 games, mean reward -13.590, speed 58.13 f/s, eps 0.02\n",
      "272057: done 142 games, mean reward -13.240, speed 58.10 f/s, eps 0.02\n",
      "275364: done 143 games, mean reward -13.000, speed 56.73 f/s, eps 0.02\n",
      "278153: done 144 games, mean reward -12.640, speed 56.44 f/s, eps 0.02\n",
      "281223: done 145 games, mean reward -12.370, speed 57.29 f/s, eps 0.02\n",
      "283583: done 146 games, mean reward -12.030, speed 57.86 f/s, eps 0.02\n",
      "285815: done 147 games, mean reward -11.670, speed 57.78 f/s, eps 0.02\n",
      "288846: done 148 games, mean reward -11.370, speed 57.23 f/s, eps 0.02\n",
      "290612: done 149 games, mean reward -10.970, speed 55.15 f/s, eps 0.02\n",
      "292855: done 150 games, mean reward -10.610, speed 55.10 f/s, eps 0.02\n",
      "295583: done 151 games, mean reward -10.300, speed 53.14 f/s, eps 0.02\n",
      "297990: done 152 games, mean reward -9.920, speed 54.62 f/s, eps 0.02\n",
      "300026: done 153 games, mean reward -9.530, speed 54.60 f/s, eps 0.02\n",
      "302352: done 154 games, mean reward -9.190, speed 55.17 f/s, eps 0.02\n",
      "304195: done 155 games, mean reward -8.800, speed 55.29 f/s, eps 0.02\n",
      "306310: done 156 games, mean reward -8.420, speed 56.27 f/s, eps 0.02\n",
      "308193: done 157 games, mean reward -8.050, speed 57.06 f/s, eps 0.02\n",
      "310480: done 158 games, mean reward -7.710, speed 57.19 f/s, eps 0.02\n",
      "312406: done 159 games, mean reward -7.320, speed 54.45 f/s, eps 0.02\n",
      "314650: done 160 games, mean reward -6.960, speed 54.71 f/s, eps 0.02\n",
      "316954: done 161 games, mean reward -6.610, speed 54.51 f/s, eps 0.02\n",
      "319009: done 162 games, mean reward -6.240, speed 54.99 f/s, eps 0.02\n",
      "321557: done 163 games, mean reward -5.910, speed 55.12 f/s, eps 0.02\n",
      "323365: done 164 games, mean reward -5.550, speed 46.12 f/s, eps 0.02\n",
      "326520: done 165 games, mean reward -5.230, speed 51.38 f/s, eps 0.02\n",
      "328350: done 166 games, mean reward -4.840, speed 54.97 f/s, eps 0.02\n",
      "330002: done 167 games, mean reward -4.430, speed 55.03 f/s, eps 0.02\n",
      "332116: done 168 games, mean reward -4.120, speed 55.27 f/s, eps 0.02\n",
      "334257: done 169 games, mean reward -3.790, speed 57.09 f/s, eps 0.02\n",
      "336481: done 170 games, mean reward -3.410, speed 57.54 f/s, eps 0.02\n",
      "338734: done 171 games, mean reward -3.070, speed 51.07 f/s, eps 0.02\n",
      "340556: done 172 games, mean reward -2.700, speed 52.89 f/s, eps 0.02\n",
      "342404: done 173 games, mean reward -2.360, speed 55.55 f/s, eps 0.02\n",
      "344688: done 174 games, mean reward -2.010, speed 55.84 f/s, eps 0.02\n",
      "346408: done 175 games, mean reward -1.690, speed 55.23 f/s, eps 0.02\n",
      "348159: done 176 games, mean reward -1.300, speed 53.71 f/s, eps 0.02\n",
      "349812: done 177 games, mean reward -0.940, speed 52.09 f/s, eps 0.02\n",
      "351738: done 178 games, mean reward -0.590, speed 50.34 f/s, eps 0.02\n",
      "353483: done 179 games, mean reward -0.210, speed 47.46 f/s, eps 0.02\n",
      "355270: done 180 games, mean reward 0.170, speed 53.08 f/s, eps 0.02\n",
      "356908: done 181 games, mean reward 0.550, speed 55.17 f/s, eps 0.02\n",
      "358665: done 182 games, mean reward 0.950, speed 51.18 f/s, eps 0.02\n",
      "360683: done 183 games, mean reward 1.260, speed 49.28 f/s, eps 0.02\n",
      "362319: done 184 games, mean reward 1.620, speed 50.00 f/s, eps 0.02\n",
      "364251: done 185 games, mean reward 1.970, speed 50.37 f/s, eps 0.02\n",
      "366325: done 186 games, mean reward 2.270, speed 48.58 f/s, eps 0.02\n",
      "368268: done 187 games, mean reward 2.620, speed 48.34 f/s, eps 0.02\n",
      "370127: done 188 games, mean reward 2.950, speed 47.81 f/s, eps 0.02\n",
      "371842: done 189 games, mean reward 3.290, speed 53.04 f/s, eps 0.02\n",
      "373794: done 190 games, mean reward 3.660, speed 50.74 f/s, eps 0.02\n",
      "375820: done 191 games, mean reward 3.990, speed 51.64 f/s, eps 0.02\n",
      "377545: done 192 games, mean reward 4.320, speed 50.92 f/s, eps 0.02\n",
      "379287: done 193 games, mean reward 4.690, speed 53.32 f/s, eps 0.02\n",
      "381352: done 194 games, mean reward 5.050, speed 52.48 f/s, eps 0.02\n",
      "383644: done 195 games, mean reward 5.350, speed 51.78 f/s, eps 0.02\n",
      "385694: done 196 games, mean reward 5.710, speed 51.59 f/s, eps 0.02\n",
      "388195: done 197 games, mean reward 6.050, speed 51.16 f/s, eps 0.02\n",
      "390076: done 198 games, mean reward 6.370, speed 52.64 f/s, eps 0.02\n",
      "392347: done 199 games, mean reward 6.700, speed 53.08 f/s, eps 0.02\n",
      "394102: done 200 games, mean reward 6.980, speed 53.01 f/s, eps 0.02\n",
      "395914: done 201 games, mean reward 7.350, speed 53.67 f/s, eps 0.02\n",
      "397929: done 202 games, mean reward 7.670, speed 54.30 f/s, eps 0.02\n",
      "400058: done 203 games, mean reward 8.030, speed 53.46 f/s, eps 0.02\n",
      "401841: done 204 games, mean reward 8.400, speed 50.42 f/s, eps 0.02\n",
      "403575: done 205 games, mean reward 8.770, speed 50.14 f/s, eps 0.02\n",
      "405395: done 206 games, mean reward 9.120, speed 51.73 f/s, eps 0.02\n",
      "408328: done 207 games, mean reward 9.380, speed 49.40 f/s, eps 0.02\n",
      "410797: done 208 games, mean reward 9.690, speed 51.75 f/s, eps 0.02\n",
      "413271: done 209 games, mean reward 9.950, speed 55.74 f/s, eps 0.02\n",
      "415106: done 210 games, mean reward 10.300, speed 50.00 f/s, eps 0.02\n",
      "417093: done 211 games, mean reward 10.600, speed 52.65 f/s, eps 0.02\n",
      "419127: done 212 games, mean reward 10.880, speed 55.30 f/s, eps 0.02\n",
      "421299: done 213 games, mean reward 11.150, speed 53.23 f/s, eps 0.02\n",
      "423210: done 214 games, mean reward 11.480, speed 52.63 f/s, eps 0.02\n",
      "425420: done 215 games, mean reward 11.750, speed 53.49 f/s, eps 0.02\n",
      "427225: done 216 games, mean reward 12.040, speed 49.61 f/s, eps 0.02\n",
      "428922: done 217 games, mean reward 12.390, speed 52.19 f/s, eps 0.02\n",
      "430662: done 218 games, mean reward 12.720, speed 51.68 f/s, eps 0.02\n",
      "432589: done 219 games, mean reward 13.020, speed 54.89 f/s, eps 0.02\n",
      "434300: done 220 games, mean reward 13.300, speed 55.45 f/s, eps 0.02\n",
      "435955: done 221 games, mean reward 13.660, speed 55.53 f/s, eps 0.02\n",
      "437993: done 222 games, mean reward 13.970, speed 57.01 f/s, eps 0.02\n",
      "439744: done 223 games, mean reward 14.240, speed 56.72 f/s, eps 0.02\n",
      "441963: done 224 games, mean reward 14.510, speed 53.99 f/s, eps 0.02\n",
      "444130: done 225 games, mean reward 14.750, speed 55.54 f/s, eps 0.02\n",
      "445770: done 226 games, mean reward 14.950, speed 52.04 f/s, eps 0.02\n",
      "447993: done 227 games, mean reward 15.230, speed 53.46 f/s, eps 0.02\n",
      "450251: done 228 games, mean reward 15.450, speed 53.12 f/s, eps 0.02\n",
      "452456: done 229 games, mean reward 15.710, speed 54.56 f/s, eps 0.02\n",
      "454530: done 230 games, mean reward 15.970, speed 48.79 f/s, eps 0.02\n",
      "456322: done 231 games, mean reward 16.150, speed 54.55 f/s, eps 0.02\n",
      "457978: done 232 games, mean reward 16.380, speed 53.66 f/s, eps 0.02\n",
      "459990: done 233 games, mean reward 16.520, speed 54.60 f/s, eps 0.02\n",
      "461844: done 234 games, mean reward 16.670, speed 52.71 f/s, eps 0.02\n",
      "463638: done 235 games, mean reward 16.800, speed 52.32 f/s, eps 0.02\n",
      "465505: done 236 games, mean reward 16.880, speed 55.67 f/s, eps 0.02\n",
      "467508: done 237 games, mean reward 16.930, speed 55.06 f/s, eps 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469266: done 238 games, mean reward 16.930, speed 52.36 f/s, eps 0.02\n",
      "470964: done 239 games, mean reward 17.040, speed 52.90 f/s, eps 0.02\n",
      "472691: done 240 games, mean reward 17.220, speed 52.99 f/s, eps 0.02\n",
      "474586: done 241 games, mean reward 17.260, speed 53.62 f/s, eps 0.02\n",
      "476649: done 242 games, mean reward 17.290, speed 53.70 f/s, eps 0.02\n",
      "478406: done 243 games, mean reward 17.470, speed 48.51 f/s, eps 0.02\n",
      "480246: done 244 games, mean reward 17.510, speed 47.22 f/s, eps 0.02\n",
      "481961: done 245 games, mean reward 17.620, speed 54.12 f/s, eps 0.02\n",
      "483993: done 246 games, mean reward 17.660, speed 54.51 f/s, eps 0.02\n",
      "485774: done 247 games, mean reward 17.700, speed 50.78 f/s, eps 0.02\n",
      "487475: done 248 games, mean reward 17.810, speed 52.81 f/s, eps 0.02\n",
      "489734: done 249 games, mean reward 17.750, speed 54.25 f/s, eps 0.02\n",
      "491525: done 250 games, mean reward 17.780, speed 52.21 f/s, eps 0.02\n",
      "493294: done 251 games, mean reward 17.860, speed 53.48 f/s, eps 0.02\n",
      "494987: done 252 games, mean reward 17.890, speed 54.52 f/s, eps 0.02\n",
      "496937: done 253 games, mean reward 17.870, speed 53.32 f/s, eps 0.02\n",
      "498718: done 254 games, mean reward 17.910, speed 54.27 f/s, eps 0.02\n",
      "500666: done 255 games, mean reward 17.900, speed 55.69 f/s, eps 0.02\n",
      "502673: done 256 games, mean reward 17.920, speed 54.65 f/s, eps 0.02\n",
      "504470: done 257 games, mean reward 17.920, speed 55.53 f/s, eps 0.02\n",
      "506495: done 258 games, mean reward 17.950, speed 55.61 f/s, eps 0.02\n",
      "508280: done 259 games, mean reward 17.950, speed 55.89 f/s, eps 0.02\n",
      "510068: done 260 games, mean reward 17.970, speed 52.84 f/s, eps 0.02\n",
      "511823: done 261 games, mean reward 18.020, speed 52.43 f/s, eps 0.02\n",
      "Solved in 511823 frames!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #input hyperparameters, check CUDA available, create environment,then we use PTAN DQN wrapper to wrap up the environment\n",
    "    params = common.HYPERPARAMS['pong']\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cuda\", default=True, action=\"store_true\", help=\"Enable cuda\")\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "    env = gym.make(params['env_name'])\n",
    "    env = ptan.common.wrappers.wrap_dqn(env)\n",
    "    \n",
    "    #we make a writer for the environment and action dimension\n",
    "    writer = SummaryWriter(comment=\"-\" + params['run_name'] + \"-basic\")\n",
    "    net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    #the wrapper below can create a copy of DQN network, which is target network, and constantly synchronize with online\n",
    "    #network\n",
    "    tgt_net = ptan.agent.TargetNet(net)\n",
    "    \n",
    "    #we create agent to change observation to action value, we also need action selector to choose the action we use\n",
    "    #We use epsilon greedy method as action selector here\n",
    "    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params['epsilon_start'])\n",
    "    epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "    agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "    \n",
    "    #experience source is from one step ExperienceSourceFirstLast and replay buffer, it will store fixed step transitions\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=params['gamma'], steps_count=1)\n",
    "    buffer = ptan.experience.ExperienceReplayBuffer(exp_source, buffer_size=params['replay_size'])\n",
    "    \n",
    "    #create optimizer and frame counter\n",
    "    optimizer = optim.Adam(net.parameters(), lr=params['learning_rate'])\n",
    "    frame_idx = 0\n",
    "    \n",
    "    #reward tracker will report mean reward when episode end, and increase frame counter by 1, also getting a transition\n",
    "    #from frame buffer.\n",
    "    #buffer.populate(1) will activate following actions:\n",
    "    #ExperienceReplayBuffer will request for next transition from experience source.\n",
    "    #Experience source will send the observation to agent to get the action\n",
    "    #Action selector which use epsilon greedy method will choose an action based on greedy or random\n",
    "    #Action will be return to experience source and input to the environment to get reward and next observation, \n",
    "    # current observation, action, reward, next observation will be stored into replay buffer\n",
    "    #transfer information will be stored in replay buffer, and oldest observation will be dropped\n",
    "    with common.RewardTracker(writer, params['stop_reward']) as reward_tracker:\n",
    "        while True:\n",
    "            frame_idx += 1\n",
    "            buffer.populate(1)\n",
    "            epsilon_tracker.frame(frame_idx)\n",
    "            \n",
    "            #check undiscounted reward list after finishing an episode, and send to reward tracker to record the data\n",
    "            #Maybe it just play one step or didn't have finished episode, if it returns true, it means the mean reward\n",
    "            #reached the reward boundary and we can break and stop training\n",
    "            new_rewards = exp_source.pop_total_rewards()\n",
    "            if new_rewards:\n",
    "                if reward_tracker.reward(new_rewards[0], frame_idx, selector.epsilon):\n",
    "                    break\n",
    "            \n",
    "            #we check buffer has cached enough data to start training or not. If not, we wait for more data.\n",
    "            if len(buffer) < params['replay_initial']:\n",
    "                continue\n",
    "            \n",
    "            #here we use Stochastic Gradient Descent(SGD) to calculate loss, zero the gradient,batch from the replay buffer\n",
    "            optimizer.zero_grad()\n",
    "            batch = buffer.sample(params['batch_size'])\n",
    "            loss_v = common.calc_loss_dqn(batch, net, tgt_net.target_model, gamma=params['gamma'], device=device)\n",
    "            loss_v.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #synchronize the target network with the online network constantly\n",
    "            if frame_idx % params['target_net_sync'] == 0:\n",
    "                tgt_net.sync()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement",
   "language": "python",
   "name": "reinforcement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
