{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06b99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from lib import dqn_model, common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa40f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES_TO_EVALUATE = 1000\n",
    "EVAL_EVERY_FRAME = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17546cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we start from first state to get q-value, and use Bellman to calculate the value\n",
    "#Same as chapter 6, the loss is the Mean Square Error of these 2 values.\n",
    "def calc_loss(batch, net, tgt_net, gamma, device=\"cpu\", double=True):\n",
    "    #we can activate or deactivate DDQN method for action\n",
    "    states, actions, rewards, dones, next_states = common.unpack_batch(batch)\n",
    "    #we pack batch data as numpy array, if parameters need CUDA device, we add to GPU.\n",
    "    states_v = torch.tensor(states).to(device)\n",
    "    next_states_v = torch.tensor(next_states).to(device)\n",
    "    actions_v = torch.tensor(actions).to(device)\n",
    "    rewards_v = torch.tensor(rewards).to(device)\n",
    "    done_mask = torch.BoolTensor(dones).to(device)\n",
    "\n",
    "    #we put the observation to the model and use gather to get the q-value. First parameterm is the parameter position\n",
    "    #we want to operate, 1 correspond to action parameter, unsqueeze will insert a new dimension,here at final position,\n",
    "    #the result is the action taken\n",
    "    #gather result is differentiable, it record the last loss gradient\n",
    "    state_action_values = net(states_v).gather(1, actions_v.unsqueeze(-1)).squeeze(-1)\n",
    "    if double:\n",
    "        #we apply next state observation to target network and calculate the largest q-value for action dimension(1).\n",
    "        #max() will return the largest value and the index at the same time, which is max and argmax, we use the value here\n",
    "        #only, therefore we get array[0]\n",
    "        next_state_actions = net(next_states_v).max(1)[1]\n",
    "        next_state_values = tgt_net(next_states_v).gather(1, next_state_actions.unsqueeze(-1)).squeeze(-1)\n",
    "    else:\n",
    "        next_state_values = tgt_net(next_states_v).max(1)[0]\n",
    "    #for the last step q-values, we set it as 0.0 for convergence because there are no next step to collect reward\n",
    "    #action value won't have next state discounted reward. If we don't set this, it won't converge.\n",
    "    next_state_values[done_mask] = 0.0\n",
    "    \n",
    "    #we calculate Bellman approximation and Mean Square Loss here\n",
    "    expected_state_action_values = next_state_values.detach() * gamma + rewards_v\n",
    "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a95889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we break the states to small pieces and pass to network to calculate action value, we choose the maximum value and\n",
    "#calculate the mean value of these maximum value\n",
    "def calc_values_of_states(states, net, device=\"cpu\"):\n",
    "    mean_vals = []\n",
    "    for batch in np.array_split(states, 64):\n",
    "        states_v = torch.tensor(batch).to(device)\n",
    "        action_values_v = net(states_v)\n",
    "        best_action_values_v = action_values_v.max(1)[0]\n",
    "        mean_vals.append(best_action_values_v.mean().item())\n",
    "    return np.mean(mean_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489638a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976: done 1 games, mean reward -21.000, speed 207.75 f/s, eps 0.99\n",
      "2099: done 2 games, mean reward -20.000, speed 232.54 f/s, eps 0.98\n",
      "3201: done 3 games, mean reward -19.667, speed 212.59 f/s, eps 0.97\n",
      "4068: done 4 games, mean reward -19.750, speed 178.91 f/s, eps 0.96\n",
      "5028: done 5 games, mean reward -19.800, speed 163.62 f/s, eps 0.95\n",
      "5968: done 6 games, mean reward -19.833, speed 165.97 f/s, eps 0.94\n",
      "6930: done 7 games, mean reward -19.857, speed 167.00 f/s, eps 0.93\n",
      "7980: done 8 games, mean reward -19.750, speed 164.06 f/s, eps 0.92\n",
      "8904: done 9 games, mean reward -19.778, speed 158.53 f/s, eps 0.91\n",
      "9892: done 10 games, mean reward -19.700, speed 165.86 f/s, eps 0.90\n",
      "10713: done 11 games, mean reward -19.818, speed 61.30 f/s, eps 0.89\n",
      "11502: done 12 games, mean reward -19.917, speed 54.02 f/s, eps 0.88\n",
      "12394: done 13 games, mean reward -19.923, speed 52.90 f/s, eps 0.88\n",
      "13328: done 14 games, mean reward -20.000, speed 52.72 f/s, eps 0.87\n",
      "14212: done 15 games, mean reward -20.000, speed 53.52 f/s, eps 0.86\n",
      "15124: done 16 games, mean reward -20.000, speed 53.32 f/s, eps 0.85\n",
      "15991: done 17 games, mean reward -20.000, speed 53.03 f/s, eps 0.84\n",
      "16829: done 18 games, mean reward -20.000, speed 52.21 f/s, eps 0.83\n",
      "17671: done 19 games, mean reward -20.053, speed 53.20 f/s, eps 0.82\n",
      "18489: done 20 games, mean reward -20.100, speed 52.10 f/s, eps 0.82\n",
      "19457: done 21 games, mean reward -20.048, speed 53.40 f/s, eps 0.81\n",
      "20446: done 22 games, mean reward -20.091, speed 52.94 f/s, eps 0.80\n",
      "21225: done 23 games, mean reward -20.130, speed 53.37 f/s, eps 0.79\n",
      "22138: done 24 games, mean reward -20.125, speed 53.25 f/s, eps 0.78\n",
      "23233: done 25 games, mean reward -20.040, speed 53.11 f/s, eps 0.77\n",
      "24050: done 26 games, mean reward -20.077, speed 53.25 f/s, eps 0.76\n",
      "25004: done 27 games, mean reward -20.074, speed 52.98 f/s, eps 0.75\n",
      "25803: done 28 games, mean reward -20.107, speed 52.79 f/s, eps 0.74\n",
      "26719: done 29 games, mean reward -20.103, speed 52.80 f/s, eps 0.73\n",
      "27505: done 30 games, mean reward -20.133, speed 52.65 f/s, eps 0.72\n",
      "28395: done 31 games, mean reward -20.129, speed 52.92 f/s, eps 0.72\n",
      "29279: done 32 games, mean reward -20.156, speed 53.13 f/s, eps 0.71\n",
      "30125: done 33 games, mean reward -20.182, speed 53.24 f/s, eps 0.70\n",
      "30901: done 34 games, mean reward -20.206, speed 53.24 f/s, eps 0.69\n",
      "31781: done 35 games, mean reward -20.229, speed 53.53 f/s, eps 0.68\n",
      "32711: done 36 games, mean reward -20.194, speed 52.56 f/s, eps 0.67\n",
      "33520: done 37 games, mean reward -20.216, speed 52.91 f/s, eps 0.66\n",
      "34327: done 38 games, mean reward -20.237, speed 53.39 f/s, eps 0.66\n",
      "35173: done 39 games, mean reward -20.256, speed 53.69 f/s, eps 0.65\n",
      "36109: done 40 games, mean reward -20.225, speed 53.43 f/s, eps 0.64\n",
      "37055: done 41 games, mean reward -20.195, speed 52.85 f/s, eps 0.63\n",
      "37903: done 42 games, mean reward -20.214, speed 53.22 f/s, eps 0.62\n",
      "38795: done 43 games, mean reward -20.209, speed 53.70 f/s, eps 0.61\n",
      "39797: done 44 games, mean reward -20.227, speed 52.75 f/s, eps 0.60\n",
      "40614: done 45 games, mean reward -20.244, speed 53.05 f/s, eps 0.59\n",
      "41459: done 46 games, mean reward -20.261, speed 52.49 f/s, eps 0.59\n",
      "42308: done 47 games, mean reward -20.277, speed 52.74 f/s, eps 0.58\n",
      "43066: done 48 games, mean reward -20.292, speed 52.58 f/s, eps 0.57\n",
      "43843: done 49 games, mean reward -20.306, speed 52.05 f/s, eps 0.56\n",
      "44678: done 50 games, mean reward -20.300, speed 52.43 f/s, eps 0.55\n",
      "45527: done 51 games, mean reward -20.314, speed 52.70 f/s, eps 0.54\n",
      "46290: done 52 games, mean reward -20.327, speed 52.73 f/s, eps 0.54\n",
      "47200: done 53 games, mean reward -20.302, speed 52.98 f/s, eps 0.53\n",
      "48006: done 54 games, mean reward -20.315, speed 52.74 f/s, eps 0.52\n",
      "48854: done 55 games, mean reward -20.327, speed 51.10 f/s, eps 0.51\n",
      "49642: done 56 games, mean reward -20.339, speed 45.54 f/s, eps 0.50\n",
      "50616: done 57 games, mean reward -20.316, speed 48.98 f/s, eps 0.49\n",
      "51457: done 58 games, mean reward -20.310, speed 50.82 f/s, eps 0.49\n",
      "52459: done 59 games, mean reward -20.288, speed 50.32 f/s, eps 0.48\n",
      "53410: done 60 games, mean reward -20.283, speed 51.44 f/s, eps 0.47\n",
      "54196: done 61 games, mean reward -20.295, speed 52.25 f/s, eps 0.46\n",
      "55017: done 62 games, mean reward -20.306, speed 51.15 f/s, eps 0.45\n",
      "55856: done 63 games, mean reward -20.317, speed 52.76 f/s, eps 0.44\n",
      "56917: done 64 games, mean reward -20.297, speed 45.48 f/s, eps 0.43\n",
      "57816: done 65 games, mean reward -20.292, speed 44.92 f/s, eps 0.42\n",
      "58651: done 66 games, mean reward -20.303, speed 42.07 f/s, eps 0.41\n",
      "59706: done 67 games, mean reward -20.313, speed 46.41 f/s, eps 0.40\n",
      "60607: done 68 games, mean reward -20.324, speed 44.13 f/s, eps 0.39\n",
      "61572: done 69 games, mean reward -20.333, speed 49.83 f/s, eps 0.38\n",
      "62466: done 70 games, mean reward -20.329, speed 46.68 f/s, eps 0.38\n",
      "63403: done 71 games, mean reward -20.338, speed 49.22 f/s, eps 0.37\n",
      "64385: done 72 games, mean reward -20.333, speed 51.14 f/s, eps 0.36\n",
      "65230: done 73 games, mean reward -20.342, speed 50.59 f/s, eps 0.35\n",
      "66113: done 74 games, mean reward -20.338, speed 51.59 f/s, eps 0.34\n",
      "67095: done 75 games, mean reward -20.333, speed 52.73 f/s, eps 0.33\n",
      "67971: done 76 games, mean reward -20.342, speed 49.94 f/s, eps 0.32\n",
      "68789: done 77 games, mean reward -20.351, speed 49.96 f/s, eps 0.31\n",
      "69789: done 78 games, mean reward -20.359, speed 51.03 f/s, eps 0.30\n",
      "70651: done 79 games, mean reward -20.354, speed 51.67 f/s, eps 0.29\n",
      "71488: done 80 games, mean reward -20.350, speed 52.15 f/s, eps 0.29\n",
      "72248: done 81 games, mean reward -20.358, speed 51.74 f/s, eps 0.28\n",
      "73085: done 82 games, mean reward -20.354, speed 52.00 f/s, eps 0.27\n",
      "74086: done 83 games, mean reward -20.361, speed 52.27 f/s, eps 0.26\n",
      "74894: done 84 games, mean reward -20.369, speed 51.53 f/s, eps 0.25\n",
      "75703: done 85 games, mean reward -20.376, speed 51.81 f/s, eps 0.24\n",
      "76490: done 86 games, mean reward -20.384, speed 52.41 f/s, eps 0.24\n",
      "77495: done 87 games, mean reward -20.368, speed 52.36 f/s, eps 0.23\n",
      "78423: done 88 games, mean reward -20.364, speed 52.15 f/s, eps 0.22\n",
      "79245: done 89 games, mean reward -20.371, speed 50.02 f/s, eps 0.21\n",
      "80005: done 90 games, mean reward -20.378, speed 51.88 f/s, eps 0.20\n",
      "80879: done 91 games, mean reward -20.385, speed 52.08 f/s, eps 0.19\n",
      "81640: done 92 games, mean reward -20.391, speed 51.97 f/s, eps 0.18\n",
      "82507: done 93 games, mean reward -20.398, speed 51.73 f/s, eps 0.17\n",
      "83355: done 94 games, mean reward -20.404, speed 51.70 f/s, eps 0.17\n",
      "84133: done 95 games, mean reward -20.411, speed 50.53 f/s, eps 0.16\n",
      "85073: done 96 games, mean reward -20.417, speed 52.10 f/s, eps 0.15\n",
      "85831: done 97 games, mean reward -20.423, speed 51.30 f/s, eps 0.14\n",
      "86772: done 98 games, mean reward -20.429, speed 51.12 f/s, eps 0.13\n",
      "87531: done 99 games, mean reward -20.434, speed 50.81 f/s, eps 0.12\n",
      "88524: done 100 games, mean reward -20.420, speed 49.94 f/s, eps 0.11\n",
      "89328: done 101 games, mean reward -20.420, speed 50.27 f/s, eps 0.11\n",
      "90113: done 102 games, mean reward -20.440, speed 51.19 f/s, eps 0.10\n",
      "91015: done 103 games, mean reward -20.460, speed 51.05 f/s, eps 0.09\n",
      "91792: done 104 games, mean reward -20.470, speed 50.35 f/s, eps 0.08\n",
      "92674: done 105 games, mean reward -20.470, speed 50.07 f/s, eps 0.07\n",
      "93460: done 106 games, mean reward -20.480, speed 51.75 f/s, eps 0.07\n",
      "94246: done 107 games, mean reward -20.490, speed 50.97 f/s, eps 0.06\n",
      "95137: done 108 games, mean reward -20.500, speed 50.85 f/s, eps 0.05\n",
      "95927: done 109 games, mean reward -20.510, speed 49.34 f/s, eps 0.04\n",
      "96689: done 110 games, mean reward -20.530, speed 52.04 f/s, eps 0.03\n",
      "97514: done 111 games, mean reward -20.530, speed 51.51 f/s, eps 0.02\n",
      "98299: done 112 games, mean reward -20.530, speed 51.32 f/s, eps 0.02\n",
      "99084: done 113 games, mean reward -20.540, speed 51.42 f/s, eps 0.02\n",
      "99908: done 114 games, mean reward -20.540, speed 51.58 f/s, eps 0.02\n",
      "100664: done 115 games, mean reward -20.550, speed 50.71 f/s, eps 0.02\n",
      "101482: done 116 games, mean reward -20.560, speed 51.90 f/s, eps 0.02\n",
      "102302: done 117 games, mean reward -20.570, speed 51.37 f/s, eps 0.02\n",
      "103137: done 118 games, mean reward -20.570, speed 52.29 f/s, eps 0.02\n",
      "103898: done 119 games, mean reward -20.570, speed 47.42 f/s, eps 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104655: done 120 games, mean reward -20.570, speed 44.36 f/s, eps 0.02\n",
      "105481: done 121 games, mean reward -20.590, speed 40.66 f/s, eps 0.02\n",
      "106272: done 122 games, mean reward -20.590, speed 44.24 f/s, eps 0.02\n",
      "107030: done 123 games, mean reward -20.590, speed 50.47 f/s, eps 0.02\n",
      "107849: done 124 games, mean reward -20.600, speed 46.66 f/s, eps 0.02\n",
      "108635: done 125 games, mean reward -20.630, speed 51.80 f/s, eps 0.02\n",
      "109439: done 126 games, mean reward -20.630, speed 51.93 f/s, eps 0.02\n",
      "110448: done 127 games, mean reward -20.620, speed 51.60 f/s, eps 0.02\n",
      "111233: done 128 games, mean reward -20.620, speed 50.95 f/s, eps 0.02\n",
      "112126: done 129 games, mean reward -20.620, speed 51.96 f/s, eps 0.02\n",
      "112945: done 130 games, mean reward -20.620, speed 52.08 f/s, eps 0.02\n",
      "113781: done 131 games, mean reward -20.620, speed 51.75 f/s, eps 0.02\n",
      "114715: done 132 games, mean reward -20.600, speed 51.64 f/s, eps 0.02\n",
      "115503: done 133 games, mean reward -20.600, speed 51.54 f/s, eps 0.02\n",
      "116479: done 134 games, mean reward -20.580, speed 48.79 f/s, eps 0.02\n",
      "117317: done 135 games, mean reward -20.570, speed 51.17 f/s, eps 0.02\n",
      "118077: done 136 games, mean reward -20.590, speed 51.19 f/s, eps 0.02\n",
      "118840: done 137 games, mean reward -20.590, speed 49.03 f/s, eps 0.02\n",
      "119625: done 138 games, mean reward -20.590, speed 51.16 f/s, eps 0.02\n",
      "120414: done 139 games, mean reward -20.590, speed 50.09 f/s, eps 0.02\n",
      "121237: done 140 games, mean reward -20.610, speed 50.48 f/s, eps 0.02\n",
      "121998: done 141 games, mean reward -20.630, speed 50.08 f/s, eps 0.02\n",
      "122759: done 142 games, mean reward -20.630, speed 50.66 f/s, eps 0.02\n",
      "123548: done 143 games, mean reward -20.640, speed 49.65 f/s, eps 0.02\n",
      "124326: done 144 games, mean reward -20.640, speed 50.49 f/s, eps 0.02\n",
      "125148: done 145 games, mean reward -20.640, speed 49.11 f/s, eps 0.02\n",
      "126012: done 146 games, mean reward -20.640, speed 47.71 f/s, eps 0.02\n",
      "126772: done 147 games, mean reward -20.640, speed 42.48 f/s, eps 0.02\n",
      "127715: done 148 games, mean reward -20.640, speed 46.81 f/s, eps 0.02\n",
      "128536: done 149 games, mean reward -20.640, speed 43.39 f/s, eps 0.02\n",
      "129358: done 150 games, mean reward -20.650, speed 46.10 f/s, eps 0.02\n",
      "130175: done 151 games, mean reward -20.650, speed 47.09 f/s, eps 0.02\n",
      "130992: done 152 games, mean reward -20.650, speed 45.55 f/s, eps 0.02\n",
      "131810: done 153 games, mean reward -20.670, speed 46.97 f/s, eps 0.02\n",
      "132717: done 154 games, mean reward -20.670, speed 48.43 f/s, eps 0.02\n",
      "133590: done 155 games, mean reward -20.660, speed 44.05 f/s, eps 0.02\n",
      "134414: done 156 games, mean reward -20.660, speed 46.39 f/s, eps 0.02\n",
      "135334: done 157 games, mean reward -20.680, speed 45.12 f/s, eps 0.02\n",
      "136231: done 158 games, mean reward -20.680, speed 43.65 f/s, eps 0.02\n",
      "137051: done 159 games, mean reward -20.700, speed 47.01 f/s, eps 0.02\n",
      "137929: done 160 games, mean reward -20.710, speed 47.76 f/s, eps 0.02\n",
      "138713: done 161 games, mean reward -20.710, speed 50.66 f/s, eps 0.02\n",
      "139530: done 162 games, mean reward -20.710, speed 49.35 f/s, eps 0.02\n",
      "140292: done 163 games, mean reward -20.710, speed 49.69 f/s, eps 0.02\n",
      "141126: done 164 games, mean reward -20.720, speed 45.31 f/s, eps 0.02\n",
      "141948: done 165 games, mean reward -20.730, speed 46.94 f/s, eps 0.02\n",
      "142785: done 166 games, mean reward -20.720, speed 50.10 f/s, eps 0.02\n",
      "143603: done 167 games, mean reward -20.720, speed 50.42 f/s, eps 0.02\n",
      "144406: done 168 games, mean reward -20.720, speed 49.91 f/s, eps 0.02\n",
      "145243: done 169 games, mean reward -20.720, speed 49.85 f/s, eps 0.02\n",
      "146001: done 170 games, mean reward -20.730, speed 49.91 f/s, eps 0.02\n",
      "146881: done 171 games, mean reward -20.730, speed 43.71 f/s, eps 0.02\n",
      "147641: done 172 games, mean reward -20.740, speed 41.04 f/s, eps 0.02\n",
      "148399: done 173 games, mean reward -20.740, speed 41.34 f/s, eps 0.02\n",
      "149219: done 174 games, mean reward -20.750, speed 45.42 f/s, eps 0.02\n",
      "150003: done 175 games, mean reward -20.760, speed 43.61 f/s, eps 0.02\n",
      "150799: done 176 games, mean reward -20.760, speed 46.26 f/s, eps 0.02\n",
      "151633: done 177 games, mean reward -20.750, speed 44.76 f/s, eps 0.02\n",
      "152540: done 178 games, mean reward -20.750, speed 49.29 f/s, eps 0.02\n",
      "153299: done 179 games, mean reward -20.760, speed 47.42 f/s, eps 0.02\n",
      "154083: done 180 games, mean reward -20.770, speed 48.53 f/s, eps 0.02\n",
      "154843: done 181 games, mean reward -20.770, speed 43.66 f/s, eps 0.02\n",
      "155599: done 182 games, mean reward -20.780, speed 46.84 f/s, eps 0.02\n",
      "156419: done 183 games, mean reward -20.780, speed 47.20 f/s, eps 0.02\n",
      "157242: done 184 games, mean reward -20.780, speed 50.13 f/s, eps 0.02\n",
      "158083: done 185 games, mean reward -20.780, speed 47.09 f/s, eps 0.02\n",
      "158859: done 186 games, mean reward -20.780, speed 49.40 f/s, eps 0.02\n",
      "159700: done 187 games, mean reward -20.790, speed 48.86 f/s, eps 0.02\n",
      "160458: done 188 games, mean reward -20.800, speed 49.81 f/s, eps 0.02\n",
      "161275: done 189 games, mean reward -20.800, speed 49.71 f/s, eps 0.02\n",
      "162097: done 190 games, mean reward -20.800, speed 49.22 f/s, eps 0.02\n",
      "162910: done 191 games, mean reward -20.800, speed 49.19 f/s, eps 0.02\n",
      "163731: done 192 games, mean reward -20.800, speed 48.47 f/s, eps 0.02\n",
      "164488: done 193 games, mean reward -20.800, speed 49.19 f/s, eps 0.02\n",
      "165245: done 194 games, mean reward -20.800, speed 49.26 f/s, eps 0.02\n",
      "166091: done 195 games, mean reward -20.800, speed 47.99 f/s, eps 0.02\n",
      "166927: done 196 games, mean reward -20.800, speed 46.13 f/s, eps 0.02\n",
      "167774: done 197 games, mean reward -20.800, speed 48.89 f/s, eps 0.02\n",
      "168594: done 198 games, mean reward -20.800, speed 49.74 f/s, eps 0.02\n",
      "169413: done 199 games, mean reward -20.800, speed 48.80 f/s, eps 0.02\n",
      "170292: done 200 games, mean reward -20.820, speed 49.34 f/s, eps 0.02\n",
      "171113: done 201 games, mean reward -20.820, speed 49.67 f/s, eps 0.02\n",
      "171870: done 202 games, mean reward -20.820, speed 49.80 f/s, eps 0.02\n",
      "172748: done 203 games, mean reward -20.820, speed 49.24 f/s, eps 0.02\n",
      "173508: done 204 games, mean reward -20.820, speed 49.22 f/s, eps 0.02\n",
      "174298: done 205 games, mean reward -20.830, speed 49.73 f/s, eps 0.02\n",
      "175054: done 206 games, mean reward -20.830, speed 48.71 f/s, eps 0.02\n",
      "175951: done 207 games, mean reward -20.830, speed 48.91 f/s, eps 0.02\n",
      "176707: done 208 games, mean reward -20.840, speed 49.23 f/s, eps 0.02\n",
      "177525: done 209 games, mean reward -20.840, speed 49.26 f/s, eps 0.02\n",
      "178302: done 210 games, mean reward -20.840, speed 48.89 f/s, eps 0.02\n",
      "179137: done 211 games, mean reward -20.830, speed 48.36 f/s, eps 0.02\n",
      "179898: done 212 games, mean reward -20.830, speed 49.39 f/s, eps 0.02\n",
      "180776: done 213 games, mean reward -20.830, speed 45.17 f/s, eps 0.02\n",
      "181616: done 214 games, mean reward -20.820, speed 44.73 f/s, eps 0.02\n",
      "182375: done 215 games, mean reward -20.820, speed 49.54 f/s, eps 0.02\n",
      "183163: done 216 games, mean reward -20.820, speed 44.57 f/s, eps 0.02\n",
      "184028: done 217 games, mean reward -20.810, speed 44.22 f/s, eps 0.02\n",
      "184784: done 218 games, mean reward -20.820, speed 46.42 f/s, eps 0.02\n",
      "185609: done 219 games, mean reward -20.820, speed 45.16 f/s, eps 0.02\n",
      "186446: done 220 games, mean reward -20.820, speed 47.91 f/s, eps 0.02\n",
      "187279: done 221 games, mean reward -20.810, speed 50.20 f/s, eps 0.02\n",
      "188123: done 222 games, mean reward -20.810, speed 41.94 f/s, eps 0.02\n",
      "188958: done 223 games, mean reward -20.800, speed 40.67 f/s, eps 0.02\n",
      "189721: done 224 games, mean reward -20.800, speed 44.95 f/s, eps 0.02\n",
      "190483: done 225 games, mean reward -20.800, speed 44.12 f/s, eps 0.02\n",
      "191358: done 226 games, mean reward -20.800, speed 40.12 f/s, eps 0.02\n",
      "192231: done 227 games, mean reward -20.820, speed 37.30 f/s, eps 0.02\n",
      "193051: done 228 games, mean reward -20.820, speed 40.81 f/s, eps 0.02\n",
      "194020: done 229 games, mean reward -20.830, speed 43.97 f/s, eps 0.02\n",
      "194866: done 230 games, mean reward -20.830, speed 46.69 f/s, eps 0.02\n",
      "195706: done 231 games, mean reward -20.830, speed 45.77 f/s, eps 0.02\n",
      "196466: done 232 games, mean reward -20.850, speed 46.04 f/s, eps 0.02\n",
      "197361: done 233 games, mean reward -20.840, speed 48.79 f/s, eps 0.02\n",
      "198119: done 234 games, mean reward -20.860, speed 49.08 f/s, eps 0.02\n",
      "198936: done 235 games, mean reward -20.870, speed 49.66 f/s, eps 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199696: done 236 games, mean reward -20.870, speed 46.75 f/s, eps 0.02\n",
      "200519: done 237 games, mean reward -20.870, speed 44.91 f/s, eps 0.02\n",
      "201280: done 238 games, mean reward -20.870, speed 47.36 f/s, eps 0.02\n",
      "202114: done 239 games, mean reward -20.860, speed 49.88 f/s, eps 0.02\n",
      "202996: done 240 games, mean reward -20.860, speed 47.89 f/s, eps 0.02\n",
      "203836: done 241 games, mean reward -20.860, speed 49.75 f/s, eps 0.02\n",
      "204732: done 242 games, mean reward -20.860, speed 50.23 f/s, eps 0.02\n",
      "205551: done 243 games, mean reward -20.860, speed 49.64 f/s, eps 0.02\n",
      "206412: done 244 games, mean reward -20.850, speed 46.13 f/s, eps 0.02\n",
      "207235: done 245 games, mean reward -20.850, speed 49.29 f/s, eps 0.02\n",
      "208054: done 246 games, mean reward -20.850, speed 50.11 f/s, eps 0.02\n",
      "208845: done 247 games, mean reward -20.850, speed 50.03 f/s, eps 0.02\n",
      "209631: done 248 games, mean reward -20.850, speed 45.85 f/s, eps 0.02\n",
      "210391: done 249 games, mean reward -20.850, speed 47.88 f/s, eps 0.02\n",
      "211148: done 250 games, mean reward -20.850, speed 47.51 f/s, eps 0.02\n",
      "211910: done 251 games, mean reward -20.850, speed 49.79 f/s, eps 0.02\n",
      "212733: done 252 games, mean reward -20.850, speed 49.31 f/s, eps 0.02\n",
      "213489: done 253 games, mean reward -20.850, speed 48.96 f/s, eps 0.02\n",
      "214248: done 254 games, mean reward -20.850, speed 49.66 f/s, eps 0.02\n",
      "215009: done 255 games, mean reward -20.860, speed 49.75 f/s, eps 0.02\n",
      "215795: done 256 games, mean reward -20.860, speed 50.22 f/s, eps 0.02\n",
      "216629: done 257 games, mean reward -20.850, speed 49.54 f/s, eps 0.02\n",
      "217511: done 258 games, mean reward -20.860, speed 49.75 f/s, eps 0.02\n",
      "218267: done 259 games, mean reward -20.860, speed 48.16 f/s, eps 0.02\n",
      "219055: done 260 games, mean reward -20.860, speed 48.00 f/s, eps 0.02\n",
      "219873: done 261 games, mean reward -20.860, speed 50.30 f/s, eps 0.02\n",
      "220707: done 262 games, mean reward -20.850, speed 49.48 f/s, eps 0.02\n",
      "221548: done 263 games, mean reward -20.840, speed 50.50 f/s, eps 0.02\n",
      "222309: done 264 games, mean reward -20.850, speed 50.33 f/s, eps 0.02\n",
      "223128: done 265 games, mean reward -20.850, speed 49.61 f/s, eps 0.02\n",
      "223951: done 266 games, mean reward -20.860, speed 47.11 f/s, eps 0.02\n",
      "224768: done 267 games, mean reward -20.860, speed 49.88 f/s, eps 0.02\n",
      "225525: done 268 games, mean reward -20.860, speed 46.61 f/s, eps 0.02\n",
      "226283: done 269 games, mean reward -20.860, speed 39.34 f/s, eps 0.02\n",
      "227200: done 270 games, mean reward -20.850, speed 44.45 f/s, eps 0.02\n",
      "227961: done 271 games, mean reward -20.850, speed 43.61 f/s, eps 0.02\n",
      "228888: done 272 games, mean reward -20.840, speed 46.99 f/s, eps 0.02\n",
      "229645: done 273 games, mean reward -20.840, speed 42.46 f/s, eps 0.02\n",
      "230485: done 274 games, mean reward -20.830, speed 49.14 f/s, eps 0.02\n",
      "231319: done 275 games, mean reward -20.820, speed 50.26 f/s, eps 0.02\n",
      "232260: done 276 games, mean reward -20.820, speed 50.19 f/s, eps 0.02\n",
      "233044: done 277 games, mean reward -20.830, speed 50.49 f/s, eps 0.02\n",
      "233925: done 278 games, mean reward -20.830, speed 48.78 f/s, eps 0.02\n",
      "234687: done 279 games, mean reward -20.830, speed 44.84 f/s, eps 0.02\n",
      "235511: done 280 games, mean reward -20.830, speed 50.24 f/s, eps 0.02\n",
      "236347: done 281 games, mean reward -20.820, speed 50.75 f/s, eps 0.02\n",
      "237169: done 282 games, mean reward -20.820, speed 51.71 f/s, eps 0.02\n",
      "237956: done 283 games, mean reward -20.820, speed 51.97 f/s, eps 0.02\n",
      "238744: done 284 games, mean reward -20.820, speed 51.92 f/s, eps 0.02\n",
      "239562: done 285 games, mean reward -20.820, speed 50.27 f/s, eps 0.02\n",
      "240380: done 286 games, mean reward -20.820, speed 51.11 f/s, eps 0.02\n",
      "241205: done 287 games, mean reward -20.830, speed 50.91 f/s, eps 0.02\n",
      "241984: done 288 games, mean reward -20.830, speed 47.80 f/s, eps 0.02\n",
      "242861: done 289 games, mean reward -20.830, speed 40.41 f/s, eps 0.02\n",
      "243624: done 290 games, mean reward -20.830, speed 42.65 f/s, eps 0.02\n",
      "244383: done 291 games, mean reward -20.830, speed 49.21 f/s, eps 0.02\n",
      "245167: done 292 games, mean reward -20.830, speed 49.94 f/s, eps 0.02\n",
      "245998: done 293 games, mean reward -20.830, speed 49.86 f/s, eps 0.02\n",
      "246795: done 294 games, mean reward -20.830, speed 49.94 f/s, eps 0.02\n",
      "247632: done 295 games, mean reward -20.830, speed 49.39 f/s, eps 0.02\n",
      "248388: done 296 games, mean reward -20.830, speed 47.80 f/s, eps 0.02\n",
      "249150: done 297 games, mean reward -20.830, speed 49.70 f/s, eps 0.02\n",
      "249981: done 298 games, mean reward -20.830, speed 48.69 f/s, eps 0.02\n",
      "250798: done 299 games, mean reward -20.830, speed 48.09 f/s, eps 0.02\n",
      "251696: done 300 games, mean reward -20.830, speed 45.52 f/s, eps 0.02\n",
      "252514: done 301 games, mean reward -20.830, speed 50.06 f/s, eps 0.02\n",
      "253270: done 302 games, mean reward -20.830, speed 50.04 f/s, eps 0.02\n",
      "254060: done 303 games, mean reward -20.830, speed 48.50 f/s, eps 0.02\n",
      "254952: done 304 games, mean reward -20.820, speed 48.21 f/s, eps 0.02\n",
      "255770: done 305 games, mean reward -20.820, speed 49.95 f/s, eps 0.02\n",
      "256560: done 306 games, mean reward -20.820, speed 49.64 f/s, eps 0.02\n",
      "257445: done 307 games, mean reward -20.820, speed 49.72 f/s, eps 0.02\n",
      "258309: done 308 games, mean reward -20.820, speed 47.29 f/s, eps 0.02\n",
      "259066: done 309 games, mean reward -20.820, speed 49.09 f/s, eps 0.02\n",
      "259829: done 310 games, mean reward -20.820, speed 48.59 f/s, eps 0.02\n",
      "260586: done 311 games, mean reward -20.830, speed 48.58 f/s, eps 0.02\n",
      "261428: done 312 games, mean reward -20.820, speed 49.82 f/s, eps 0.02\n",
      "262190: done 313 games, mean reward -20.820, speed 50.01 f/s, eps 0.02\n",
      "262953: done 314 games, mean reward -20.830, speed 49.35 f/s, eps 0.02\n",
      "263728: done 315 games, mean reward -20.830, speed 49.78 f/s, eps 0.02\n",
      "264488: done 316 games, mean reward -20.830, speed 49.07 f/s, eps 0.02\n",
      "265245: done 317 games, mean reward -20.840, speed 49.94 f/s, eps 0.02\n",
      "266033: done 318 games, mean reward -20.840, speed 49.55 f/s, eps 0.02\n",
      "266855: done 319 games, mean reward -20.840, speed 45.47 f/s, eps 0.02\n",
      "267689: done 320 games, mean reward -20.830, speed 49.39 f/s, eps 0.02\n",
      "268498: done 321 games, mean reward -20.840, speed 50.00 f/s, eps 0.02\n",
      "269381: done 322 games, mean reward -20.840, speed 47.63 f/s, eps 0.02\n",
      "270202: done 323 games, mean reward -20.850, speed 49.80 f/s, eps 0.02\n",
      "270979: done 324 games, mean reward -20.850, speed 49.43 f/s, eps 0.02\n",
      "271740: done 325 games, mean reward -20.850, speed 49.56 f/s, eps 0.02\n",
      "272621: done 326 games, mean reward -20.850, speed 48.57 f/s, eps 0.02\n",
      "273406: done 327 games, mean reward -20.850, speed 46.56 f/s, eps 0.02\n",
      "274169: done 328 games, mean reward -20.850, speed 45.56 f/s, eps 0.02\n",
      "274931: done 329 games, mean reward -20.850, speed 48.53 f/s, eps 0.02\n",
      "275795: done 330 games, mean reward -20.840, speed 49.15 f/s, eps 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7f6da715cd37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mframe_idx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mepsilon_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36mpopulate\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperience_source_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExperienceSourceFirstLast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[0mlast_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\ptan\\experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m                     \u001b[0mstates_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstates_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                 \u001b[0mstates_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_agent_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mg_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstates_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\ptan\\agent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, states, agent_states)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mq_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\reinforcement learning\\Chapter 7\\lib\\dqn_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mconv_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\reinforcement\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    914\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #input hyperparameters, check CUDA available, create environment,then we use PTAN DQN wrapper to wrap up the environment\n",
    "    params = common.HYPERPARAMS['pong']\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cuda\", default=True, action=\"store_true\", help=\"Enable cuda\")\n",
    "    #we can activate Double DQN at following line.\n",
    "    parser.add_argument(\"--double\", default=True, action=\"store_true\", help=\"Enable double DQN\")\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "    env = gym.make(params['env_name'])\n",
    "    env = ptan.common.wrappers.wrap_dqn(env)\n",
    "\n",
    "    #we make a writer for the environment and action dimension\n",
    "    writer = SummaryWriter(comment=\"-\" + params['run_name'] + \"-double=\" + str(args.double))\n",
    "    net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "\n",
    "    #the wrapper below can create a copy of DQN network, which is target network, and constantly synchronize with online\n",
    "    #network\n",
    "    tgt_net = ptan.agent.TargetNet(net)\n",
    "    #we create agent to change observation to action value, we also need action selector to choose the action we use\n",
    "    #We use epsilon greedy method as action selector here\n",
    "    selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params['epsilon_start'])\n",
    "    epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "    agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "\n",
    "    #experience source is from one step ExperienceSourceFirstLast and replay buffer, it will store fixed step transitions\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=params['gamma'], steps_count=1)\n",
    "    buffer = ptan.experience.ExperienceReplayBuffer(exp_source, buffer_size=params['replay_size'])\n",
    "    #create optimizer and frame counter\n",
    "    optimizer = optim.Adam(net.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    frame_idx = 0\n",
    "    #we initialize evaluation state value\n",
    "    eval_states = None\n",
    "\n",
    "    #reward tracker will report mean reward when episode end, and increase frame counter by 1, also getting a transition\n",
    "    #from frame buffer.\n",
    "    #buffer.populate(1) will activate following actions:\n",
    "    #ExperienceReplayBuffer will request for next transition from experience source.\n",
    "    #Experience source will send the observation to agent to get the action\n",
    "    #Action selector which use epsilon greedy method will choose an action based on greedy or random\n",
    "    #Action will be return to experience source and input to the environment to get reward and next observation, \n",
    "    # current observation, action, reward, next observation will be stored into replay buffer\n",
    "    #transfer information will be stored in replay buffer, and oldest observation will be dropped\n",
    "    with common.RewardTracker(writer, params['stop_reward']) as reward_tracker:\n",
    "        while True:\n",
    "            frame_idx += 1\n",
    "            buffer.populate(1)\n",
    "            epsilon_tracker.frame(frame_idx)\n",
    "\n",
    "            #check undiscounted reward list after finishing an episode, and send to reward tracker to record the data\n",
    "            #Maybe it just play one step or didn't have finished episode, if it returns true, it means the mean reward\n",
    "            #reached the reward boundary and we can break and stop training\n",
    "            new_rewards = exp_source.pop_total_rewards()\n",
    "            if new_rewards:\n",
    "                if reward_tracker.reward(new_rewards[0], frame_idx, selector.epsilon):\n",
    "                    break\n",
    "\n",
    "            #we check buffer has cached enough data to start training or not. If not, we wait for more data.\n",
    "            if len(buffer) < params['replay_initial']:\n",
    "                continue\n",
    "            #we construct states for evaluation, and set STATES_TO_EVALUATE to 1000 to evaluate 1000 states at once.\n",
    "            if eval_states is None:\n",
    "                eval_states = buffer.sample(STATES_TO_EVALUATE)\n",
    "                eval_states = [np.array(transition.state, copy=False) for transition in eval_states]\n",
    "                eval_states = np.array(eval_states, copy=False)\n",
    "\n",
    "            #here we use Stochastic Gradient Descent(SGD) to calculate loss, zero the gradient,batch from the replay buffer\n",
    "            optimizer.zero_grad()\n",
    "            batch = buffer.sample(params['batch_size'])\n",
    "            #We use the calc_loss_dqn in this file instead of the one in common.py\n",
    "            loss_v = calc_loss(batch, net, tgt_net.target_model, gamma=params['gamma'], device=device, double=args.double)\n",
    "            loss_v.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #synchronize the target network with the online network constantly\n",
    "            if frame_idx % params['target_net_sync'] == 0:\n",
    "                tgt_net.sync()\n",
    "            #for every EVAL_EVERY_FRAME(100) frames, we calculate the mean value of states and write to TensorBoard\n",
    "            if frame_idx % EVAL_EVERY_FRAME == 0:\n",
    "                mean_val = calc_values_of_states(eval_states, net, device=device)\n",
    "                writer.add_scalar(\"values_mean\", mean_val, frame_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb33d5",
   "metadata": {},
   "source": [
    "# Warning: code above is not stable, it will either converge or diverge at start, don't use above code to finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce21fcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(reinforcement) C:\\Users\\Kelvin\\Desktop\\reinforcement learning\\Chapter 7>python 03_dqn_double.py --cuda --double\n",
      "864: done 1 games, mean reward -20.000, speed 206.26 f/s, eps 0.99\n",
      "1698: done 2 games, mean reward -20.000, speed 243.38 f/s, eps 0.98\n",
      "2568: done 3 games, mean reward -20.333, speed 234.62 f/s, eps 0.97\n",
      "3387: done 4 games, mean reward -20.500, speed 192.72 f/s, eps 0.97\n",
      "4430: done 5 games, mean reward -20.400, speed 169.30 f/s, eps 0.96\n",
      "5455: done 6 games, mean reward -20.500, speed 166.49 f/s, eps 0.95\n",
      "6457: done 7 games, mean reward -20.429, speed 167.25 f/s, eps 0.94\n",
      "7235: done 8 games, mean reward -20.500, speed 166.22 f/s, eps 0.93\n",
      "8023: done 9 games, mean reward -20.556, speed 162.44 f/s, eps 0.92\n",
      "8829: done 10 games, mean reward -20.600, speed 162.87 f/s, eps 0.91\n",
      "9687: done 11 games, mean reward -20.545, speed 160.62 f/s, eps 0.90\n",
      "10510: done 12 games, mean reward -20.583, speed 71.02 f/s, eps 0.89\n",
      "11268: done 13 games, mean reward -20.615, speed 53.47 f/s, eps 0.89\n",
      "12212: done 14 games, mean reward -20.571, speed 53.16 f/s, eps 0.88\n",
      "13170: done 15 games, mean reward -20.533, speed 52.59 f/s, eps 0.87\n",
      "14122: done 16 games, mean reward -20.438, speed 50.51 f/s, eps 0.86\n",
      "15078: done 17 games, mean reward -20.412, speed 51.47 f/s, eps 0.85\n",
      "15950: done 18 games, mean reward -20.444, speed 53.02 f/s, eps 0.84\n",
      "16830: done 19 games, mean reward -20.474, speed 53.59 f/s, eps 0.83\n",
      "17739: done 20 games, mean reward -20.500, speed 53.12 f/s, eps 0.82\n",
      "18664: done 21 games, mean reward -20.524, speed 52.98 f/s, eps 0.81\n",
      "19622: done 22 games, mean reward -20.545, speed 53.45 f/s, eps 0.80\n",
      "20503: done 23 games, mean reward -20.565, speed 53.53 f/s, eps 0.79\n",
      "21353: done 24 games, mean reward -20.583, speed 52.86 f/s, eps 0.79\n",
      "22275: done 25 games, mean reward -20.560, speed 50.99 f/s, eps 0.78\n",
      "23167: done 26 games, mean reward -20.538, speed 49.62 f/s, eps 0.77\n",
      "23990: done 27 games, mean reward -20.556, speed 51.43 f/s, eps 0.76\n",
      "24886: done 28 games, mean reward -20.571, speed 51.38 f/s, eps 0.75\n",
      "25648: done 29 games, mean reward -20.586, speed 50.53 f/s, eps 0.74\n",
      "26470: done 30 games, mean reward -20.600, speed 51.70 f/s, eps 0.74\n",
      "27422: done 31 games, mean reward -20.581, speed 51.20 f/s, eps 0.73\n",
      "28488: done 32 games, mean reward -20.531, speed 52.06 f/s, eps 0.72\n",
      "29245: done 33 games, mean reward -20.545, speed 52.80 f/s, eps 0.71\n",
      "30193: done 34 games, mean reward -20.529, speed 53.09 f/s, eps 0.70\n",
      "31032: done 35 games, mean reward -20.543, speed 52.75 f/s, eps 0.69\n",
      "31944: done 36 games, mean reward -20.528, speed 53.21 f/s, eps 0.68\n",
      "32987: done 37 games, mean reward -20.486, speed 52.48 f/s, eps 0.67\n",
      "33810: done 38 games, mean reward -20.500, speed 52.17 f/s, eps 0.66\n",
      "34819: done 39 games, mean reward -20.487, speed 50.67 f/s, eps 0.65\n",
      "35849: done 40 games, mean reward -20.500, speed 50.79 f/s, eps 0.64\n",
      "36668: done 41 games, mean reward -20.512, speed 51.83 f/s, eps 0.63\n",
      "37482: done 42 games, mean reward -20.524, speed 52.28 f/s, eps 0.63\n",
      "38274: done 43 games, mean reward -20.535, speed 51.60 f/s, eps 0.62\n",
      "39061: done 44 games, mean reward -20.545, speed 52.68 f/s, eps 0.61\n",
      "40153: done 45 games, mean reward -20.533, speed 51.09 f/s, eps 0.60\n",
      "41200: done 46 games, mean reward -20.522, speed 50.70 f/s, eps 0.59\n",
      "42078: done 47 games, mean reward -20.532, speed 51.89 f/s, eps 0.58\n",
      "42974: done 48 games, mean reward -20.521, speed 52.18 f/s, eps 0.57\n",
      "43892: done 49 games, mean reward -20.510, speed 52.18 f/s, eps 0.56\n",
      "44853: done 50 games, mean reward -20.480, speed 47.61 f/s, eps 0.55\n",
      "45690: done 51 games, mean reward -20.471, speed 48.09 f/s, eps 0.54\n",
      "46565: done 52 games, mean reward -20.481, speed 51.69 f/s, eps 0.53\n",
      "47384: done 53 games, mean reward -20.491, speed 46.87 f/s, eps 0.53\n",
      "48263: done 54 games, mean reward -20.500, speed 48.66 f/s, eps 0.52\n",
      "49099: done 55 games, mean reward -20.491, speed 47.92 f/s, eps 0.51\n",
      "49919: done 56 games, mean reward -20.500, speed 48.96 f/s, eps 0.50\n",
      "50710: done 57 games, mean reward -20.509, speed 47.78 f/s, eps 0.49\n",
      "51618: done 58 games, mean reward -20.500, speed 51.55 f/s, eps 0.48\n",
      "52509: done 59 games, mean reward -20.492, speed 51.65 f/s, eps 0.47\n",
      "53391: done 60 games, mean reward -20.500, speed 51.64 f/s, eps 0.47\n",
      "54209: done 61 games, mean reward -20.508, speed 50.71 f/s, eps 0.46\n",
      "55054: done 62 games, mean reward -20.516, speed 52.42 f/s, eps 0.45\n",
      "55961: done 63 games, mean reward -20.524, speed 52.09 f/s, eps 0.44\n",
      "56782: done 64 games, mean reward -20.531, speed 51.49 f/s, eps 0.43\n",
      "57687: done 65 games, mean reward -20.538, speed 51.64 f/s, eps 0.42\n",
      "58692: done 66 games, mean reward -20.515, speed 51.55 f/s, eps 0.41\n",
      "59541: done 67 games, mean reward -20.522, speed 51.82 f/s, eps 0.40\n",
      "60349: done 68 games, mean reward -20.529, speed 51.77 f/s, eps 0.40\n",
      "61233: done 69 games, mean reward -20.536, speed 52.50 f/s, eps 0.39\n",
      "62190: done 70 games, mean reward -20.529, speed 49.77 f/s, eps 0.38\n",
      "63058: done 71 games, mean reward -20.521, speed 50.72 f/s, eps 0.37\n",
      "64023: done 72 games, mean reward -20.528, speed 49.10 f/s, eps 0.36\n",
      "64846: done 73 games, mean reward -20.534, speed 47.38 f/s, eps 0.35\n",
      "65786: done 74 games, mean reward -20.541, speed 52.03 f/s, eps 0.34\n",
      "66606: done 75 games, mean reward -20.547, speed 50.61 f/s, eps 0.33\n",
      "67581: done 76 games, mean reward -20.526, speed 51.64 f/s, eps 0.32\n",
      "68493: done 77 games, mean reward -20.519, speed 50.92 f/s, eps 0.32\n",
      "69465: done 78 games, mean reward -20.526, speed 52.01 f/s, eps 0.31\n",
      "70345: done 79 games, mean reward -20.532, speed 52.11 f/s, eps 0.30\n",
      "71379: done 80 games, mean reward -20.512, speed 52.44 f/s, eps 0.29\n",
      "72160: done 81 games, mean reward -20.519, speed 51.94 f/s, eps 0.28\n",
      "73156: done 82 games, mean reward -20.524, speed 50.89 f/s, eps 0.27\n",
      "73991: done 83 games, mean reward -20.518, speed 52.62 f/s, eps 0.26\n",
      "74825: done 84 games, mean reward -20.512, speed 52.23 f/s, eps 0.25\n",
      "75744: done 85 games, mean reward -20.506, speed 52.30 f/s, eps 0.24\n",
      "76519: done 86 games, mean reward -20.512, speed 52.58 f/s, eps 0.23\n",
      "77550: done 87 games, mean reward -20.517, speed 52.42 f/s, eps 0.22\n",
      "78525: done 88 games, mean reward -20.500, speed 51.68 f/s, eps 0.21\n",
      "79359: done 89 games, mean reward -20.494, speed 52.40 f/s, eps 0.21\n",
      "80238: done 90 games, mean reward -20.500, speed 51.92 f/s, eps 0.20\n",
      "81385: done 91 games, mean reward -20.495, speed 52.95 f/s, eps 0.19\n",
      "82319: done 92 games, mean reward -20.500, speed 51.87 f/s, eps 0.18\n",
      "83425: done 93 games, mean reward -20.495, speed 51.31 f/s, eps 0.17\n",
      "84650: done 94 games, mean reward -20.489, speed 51.74 f/s, eps 0.15\n",
      "85735: done 95 games, mean reward -20.484, speed 53.00 f/s, eps 0.14\n",
      "86916: done 96 games, mean reward -20.479, speed 52.11 f/s, eps 0.13\n",
      "88456: done 97 games, mean reward -20.464, speed 50.60 f/s, eps 0.12\n",
      "89478: done 98 games, mean reward -20.459, speed 52.14 f/s, eps 0.11\n",
      "90664: done 99 games, mean reward -20.465, speed 51.89 f/s, eps 0.09\n",
      "91923: done 100 games, mean reward -20.460, speed 49.96 f/s, eps 0.08\n",
      "92962: done 101 games, mean reward -20.470, speed 50.57 f/s, eps 0.07\n",
      "94106: done 102 games, mean reward -20.480, speed 50.10 f/s, eps 0.06\n",
      "95355: done 103 games, mean reward -20.470, speed 50.42 f/s, eps 0.05\n",
      "96439: done 104 games, mean reward -20.470, speed 49.82 f/s, eps 0.04\n",
      "97750: done 105 games, mean reward -20.480, speed 50.49 f/s, eps 0.02\n",
      "99170: done 106 games, mean reward -20.460, speed 50.15 f/s, eps 0.02\n",
      "100020: done 107 games, mean reward -20.470, speed 50.77 f/s, eps 0.02\n",
      "101100: done 108 games, mean reward -20.470, speed 50.43 f/s, eps 0.02\n",
      "102473: done 109 games, mean reward -20.470, speed 50.71 f/s, eps 0.02\n",
      "103771: done 110 games, mean reward -20.450, speed 50.86 f/s, eps 0.02\n",
      "105649: done 111 games, mean reward -20.430, speed 50.74 f/s, eps 0.02\n",
      "106751: done 112 games, mean reward -20.420, speed 50.59 f/s, eps 0.02\n",
      "108329: done 113 games, mean reward -20.400, speed 50.71 f/s, eps 0.02\n",
      "110360: done 114 games, mean reward -20.370, speed 51.07 f/s, eps 0.02\n",
      "112886: done 115 games, mean reward -20.310, speed 50.69 f/s, eps 0.02\n",
      "114597: done 116 games, mean reward -20.310, speed 50.81 f/s, eps 0.02\n",
      "116125: done 117 games, mean reward -20.300, speed 50.80 f/s, eps 0.02\n",
      "117849: done 118 games, mean reward -20.290, speed 50.54 f/s, eps 0.02\n",
      "119800: done 119 games, mean reward -20.250, speed 50.18 f/s, eps 0.02\n",
      "121571: done 120 games, mean reward -20.230, speed 47.72 f/s, eps 0.02\n",
      "123464: done 121 games, mean reward -20.190, speed 48.27 f/s, eps 0.02\n",
      "125212: done 122 games, mean reward -20.180, speed 49.28 f/s, eps 0.02\n",
      "126790: done 123 games, mean reward -20.170, speed 48.92 f/s, eps 0.02\n",
      "128521: done 124 games, mean reward -20.130, speed 48.47 f/s, eps 0.02\n",
      "130205: done 125 games, mean reward -20.120, speed 49.22 f/s, eps 0.02\n",
      "132053: done 126 games, mean reward -20.100, speed 50.58 f/s, eps 0.02\n",
      "133757: done 127 games, mean reward -20.090, speed 51.01 f/s, eps 0.02\n",
      "135845: done 128 games, mean reward -20.050, speed 50.71 f/s, eps 0.02\n",
      "137537: done 129 games, mean reward -20.050, speed 50.67 f/s, eps 0.02\n",
      "139604: done 130 games, mean reward -19.990, speed 50.45 f/s, eps 0.02\n",
      "141443: done 131 games, mean reward -19.980, speed 50.56 f/s, eps 0.02\n",
      "143387: done 132 games, mean reward -19.960, speed 50.66 f/s, eps 0.02\n",
      "145366: done 133 games, mean reward -19.960, speed 50.68 f/s, eps 0.02\n",
      "147575: done 134 games, mean reward -19.940, speed 50.71 f/s, eps 0.02\n",
      "149694: done 135 games, mean reward -19.910, speed 50.80 f/s, eps 0.02\n",
      "152125: done 136 games, mean reward -19.900, speed 50.61 f/s, eps 0.02\n",
      "154340: done 137 games, mean reward -19.880, speed 50.46 f/s, eps 0.02\n",
      "156462: done 138 games, mean reward -19.820, speed 50.31 f/s, eps 0.02\n",
      "158131: done 139 games, mean reward -19.820, speed 50.40 f/s, eps 0.02\n",
      "160285: done 140 games, mean reward -19.790, speed 50.41 f/s, eps 0.02\n",
      "162398: done 141 games, mean reward -19.760, speed 50.46 f/s, eps 0.02\n",
      "164392: done 142 games, mean reward -19.740, speed 50.66 f/s, eps 0.02\n",
      "166943: done 143 games, mean reward -19.670, speed 50.46 f/s, eps 0.02\n",
      "169153: done 144 games, mean reward -19.640, speed 50.56 f/s, eps 0.02\n",
      "171775: done 145 games, mean reward -19.620, speed 50.14 f/s, eps 0.02\n",
      "173887: done 146 games, mean reward -19.610, speed 50.33 f/s, eps 0.02\n",
      "175783: done 147 games, mean reward -19.560, speed 48.52 f/s, eps 0.02\n",
      "177817: done 148 games, mean reward -19.550, speed 50.16 f/s, eps 0.02\n",
      "179725: done 149 games, mean reward -19.540, speed 50.41 f/s, eps 0.02\n",
      "182400: done 150 games, mean reward -19.480, speed 50.73 f/s, eps 0.02\n",
      "185319: done 151 games, mean reward -19.410, speed 50.49 f/s, eps 0.02\n",
      "188022: done 152 games, mean reward -19.330, speed 49.86 f/s, eps 0.02\n",
      "190437: done 153 games, mean reward -19.320, speed 50.58 f/s, eps 0.02\n",
      "192844: done 154 games, mean reward -19.270, speed 50.90 f/s, eps 0.02\n",
      "195200: done 155 games, mean reward -19.210, speed 50.46 f/s, eps 0.02\n",
      "197653: done 156 games, mean reward -19.130, speed 50.53 f/s, eps 0.02\n",
      "200461: done 157 games, mean reward -18.990, speed 50.93 f/s, eps 0.02\n",
      "203304: done 158 games, mean reward -18.920, speed 50.86 f/s, eps 0.02\n",
      "205985: done 159 games, mean reward -18.840, speed 50.53 f/s, eps 0.02\n",
      "207719: done 160 games, mean reward -18.820, speed 50.33 f/s, eps 0.02\n",
      "209778: done 161 games, mean reward -18.780, speed 50.72 f/s, eps 0.02\n",
      "212381: done 162 games, mean reward -18.630, speed 50.38 f/s, eps 0.02\n",
      "214492: done 163 games, mean reward -18.580, speed 50.61 f/s, eps 0.02\n",
      "217354: done 164 games, mean reward -18.430, speed 50.64 f/s, eps 0.02\n",
      "219569: done 165 games, mean reward -18.370, speed 50.74 f/s, eps 0.02\n",
      "222518: done 166 games, mean reward -18.300, speed 50.71 f/s, eps 0.02\n",
      "225337: done 167 games, mean reward -18.240, speed 50.47 f/s, eps 0.02\n",
      "228316: done 168 games, mean reward -17.960, speed 50.60 f/s, eps 0.02\n",
      "230939: done 169 games, mean reward -17.810, speed 50.64 f/s, eps 0.02\n",
      "233843: done 170 games, mean reward -17.650, speed 50.45 f/s, eps 0.02\n",
      "236076: done 171 games, mean reward -17.580, speed 50.53 f/s, eps 0.02\n",
      "238276: done 172 games, mean reward -17.520, speed 50.77 f/s, eps 0.02\n",
      "240995: done 173 games, mean reward -17.410, speed 50.82 f/s, eps 0.02\n",
      "243835: done 174 games, mean reward -17.260, speed 50.32 f/s, eps 0.02\n",
      "246324: done 175 games, mean reward -17.190, speed 50.29 f/s, eps 0.02\n",
      "248862: done 176 games, mean reward -17.080, speed 50.41 f/s, eps 0.02\n",
      "251885: done 177 games, mean reward -16.920, speed 50.76 f/s, eps 0.02\n",
      "253884: done 178 games, mean reward -16.880, speed 50.40 f/s, eps 0.02\n",
      "256382: done 179 games, mean reward -16.790, speed 50.79 f/s, eps 0.02\n",
      "259162: done 180 games, mean reward -16.690, speed 50.60 f/s, eps 0.02\n",
      "261928: done 181 games, mean reward -16.570, speed 50.83 f/s, eps 0.02\n",
      "265054: done 182 games, mean reward -16.400, speed 50.83 f/s, eps 0.02\n",
      "267814: done 183 games, mean reward -16.270, speed 50.82 f/s, eps 0.02\n",
      "269473: done 184 games, mean reward -16.250, speed 50.87 f/s, eps 0.02\n",
      "272782: done 185 games, mean reward -16.030, speed 50.77 f/s, eps 0.02\n",
      "274592: done 186 games, mean reward -16.020, speed 50.61 f/s, eps 0.02\n",
      "277562: done 187 games, mean reward -15.880, speed 50.55 f/s, eps 0.02\n",
      "280431: done 188 games, mean reward -15.710, speed 50.31 f/s, eps 0.02\n",
      "283220: done 189 games, mean reward -15.430, speed 50.90 f/s, eps 0.02\n",
      "286142: done 190 games, mean reward -15.260, speed 50.76 f/s, eps 0.02\n",
      "288443: done 191 games, mean reward -14.970, speed 51.05 f/s, eps 0.02\n",
      "291605: done 192 games, mean reward -14.800, speed 50.66 f/s, eps 0.02\n",
      "293850: done 193 games, mean reward -14.480, speed 50.70 f/s, eps 0.02\n",
      "296928: done 194 games, mean reward -14.250, speed 50.58 f/s, eps 0.02\n",
      "299970: done 195 games, mean reward -14.070, speed 50.92 f/s, eps 0.02\n",
      "301895: done 196 games, mean reward -13.690, speed 50.52 f/s, eps 0.02\n",
      "304081: done 197 games, mean reward -13.360, speed 50.76 f/s, eps 0.02\n",
      "307098: done 198 games, mean reward -13.120, speed 50.00 f/s, eps 0.02\n",
      "309260: done 199 games, mean reward -13.040, speed 50.20 f/s, eps 0.02\n",
      "311599: done 200 games, mean reward -12.720, speed 50.78 f/s, eps 0.02\n",
      "313588: done 201 games, mean reward -12.370, speed 50.63 f/s, eps 0.02\n",
      "316951: done 202 games, mean reward -12.150, speed 50.33 f/s, eps 0.02\n",
      "319500: done 203 games, mean reward -11.850, speed 50.51 f/s, eps 0.02\n",
      "322916: done 204 games, mean reward -11.750, speed 50.23 f/s, eps 0.02\n",
      "325028: done 205 games, mean reward -11.370, speed 50.09 f/s, eps 0.02\n",
      "326751: done 206 games, mean reward -10.980, speed 50.68 f/s, eps 0.02\n",
      "328578: done 207 games, mean reward -10.580, speed 49.78 f/s, eps 0.02\n",
      "332093: done 208 games, mean reward -10.340, speed 50.46 f/s, eps 0.02\n",
      "334047: done 209 games, mean reward -9.960, speed 49.74 f/s, eps 0.02\n",
      "336341: done 210 games, mean reward -9.980, speed 50.34 f/s, eps 0.02\n",
      "339229: done 211 games, mean reward -9.830, speed 50.16 f/s, eps 0.02\n",
      "341214: done 212 games, mean reward -9.490, speed 46.60 f/s, eps 0.02\n",
      "344215: done 213 games, mean reward -9.240, speed 45.38 f/s, eps 0.02\n",
      "346411: done 214 games, mean reward -8.900, speed 42.35 f/s, eps 0.02\n",
      "348506: done 215 games, mean reward -8.620, speed 44.06 f/s, eps 0.02\n",
      "350613: done 216 games, mean reward -8.270, speed 29.75 f/s, eps 0.02\n",
      "354021: done 217 games, mean reward -8.030, speed 43.44 f/s, eps 0.02\n",
      "356144: done 218 games, mean reward -7.670, speed 44.32 f/s, eps 0.02\n",
      "358025: done 219 games, mean reward -7.320, speed 44.47 f/s, eps 0.02\n",
      "359958: done 220 games, mean reward -6.960, speed 45.50 f/s, eps 0.02\n",
      "361651: done 221 games, mean reward -6.580, speed 44.44 f/s, eps 0.02\n",
      "363793: done 222 games, mean reward -6.210, speed 47.85 f/s, eps 0.02\n",
      "365634: done 223 games, mean reward -5.830, speed 45.39 f/s, eps 0.02\n",
      "367421: done 224 games, mean reward -5.480, speed 45.94 f/s, eps 0.02\n",
      "370657: done 225 games, mean reward -5.300, speed 46.70 f/s, eps 0.02\n",
      "372393: done 226 games, mean reward -4.920, speed 45.70 f/s, eps 0.02\n",
      "374212: done 227 games, mean reward -4.540, speed 47.56 f/s, eps 0.02\n",
      "376019: done 228 games, mean reward -4.190, speed 44.61 f/s, eps 0.02\n",
      "377959: done 229 games, mean reward -3.800, speed 46.54 f/s, eps 0.02\n",
      "379780: done 230 games, mean reward -3.460, speed 47.10 f/s, eps 0.02\n",
      "381444: done 231 games, mean reward -3.070, speed 45.65 f/s, eps 0.02\n",
      "383431: done 232 games, mean reward -2.700, speed 46.24 f/s, eps 0.02\n",
      "385610: done 233 games, mean reward -2.330, speed 46.07 f/s, eps 0.02\n",
      "387314: done 234 games, mean reward -1.950, speed 46.21 f/s, eps 0.02\n",
      "389509: done 235 games, mean reward -1.610, speed 46.20 f/s, eps 0.02\n",
      "391141: done 236 games, mean reward -1.210, speed 39.42 f/s, eps 0.02\n",
      "394471: done 237 games, mean reward -1.000, speed 43.26 f/s, eps 0.02\n",
      "397583: done 238 games, mean reward -0.790, speed 2.68 f/s, eps 0.02\n",
      "399443: done 239 games, mean reward -0.420, speed 43.52 f/s, eps 0.02\n",
      "401575: done 240 games, mean reward -0.090, speed 46.02 f/s, eps 0.02\n",
      "403257: done 241 games, mean reward 0.290, speed 47.32 f/s, eps 0.02\n",
      "405439: done 242 games, mean reward 0.630, speed 2.80 f/s, eps 0.02\n",
      "408694: done 243 games, mean reward 0.780, speed 44.89 f/s, eps 0.02\n",
      "410744: done 244 games, mean reward 1.120, speed 47.17 f/s, eps 0.02\n",
      "412996: done 245 games, mean reward 1.440, speed 46.07 f/s, eps 0.02\n",
      "415982: done 246 games, mean reward 1.670, speed 45.85 f/s, eps 0.02\n",
      "417981: done 247 games, mean reward 2.010, speed 45.59 f/s, eps 0.02\n",
      "419971: done 248 games, mean reward 2.380, speed 45.62 f/s, eps 0.02\n",
      "422242: done 249 games, mean reward 2.730, speed 47.19 f/s, eps 0.02\n",
      "423873: done 250 games, mean reward 3.070, speed 47.07 f/s, eps 0.02\n",
      "425647: done 251 games, mean reward 3.390, speed 47.06 f/s, eps 0.02\n",
      "427462: done 252 games, mean reward 3.720, speed 46.73 f/s, eps 0.02\n",
      "429885: done 253 games, mean reward 4.040, speed 46.21 f/s, eps 0.02\n",
      "432606: done 254 games, mean reward 4.300, speed 46.53 f/s, eps 0.02\n",
      "434459: done 255 games, mean reward 4.620, speed 46.84 f/s, eps 0.02\n",
      "436509: done 256 games, mean reward 4.620, speed 45.54 f/s, eps 0.02\n",
      "438559: done 257 games, mean reward 4.850, speed 46.96 f/s, eps 0.02\n",
      "440431: done 258 games, mean reward 5.170, speed 45.82 f/s, eps 0.02\n",
      "443187: done 259 games, mean reward 5.370, speed 42.31 f/s, eps 0.02\n",
      "445049: done 260 games, mean reward 5.740, speed 49.60 f/s, eps 0.02\n",
      "446949: done 261 games, mean reward 6.090, speed 50.26 f/s, eps 0.02\n",
      "449146: done 262 games, mean reward 6.280, speed 50.41 f/s, eps 0.02\n",
      "451388: done 263 games, mean reward 6.600, speed 50.71 f/s, eps 0.02\n",
      "453160: done 264 games, mean reward 6.860, speed 50.39 f/s, eps 0.02\n",
      "455005: done 265 games, mean reward 7.200, speed 50.40 f/s, eps 0.02\n",
      "457310: done 266 games, mean reward 7.450, speed 50.40 f/s, eps 0.02\n",
      "458967: done 267 games, mean reward 7.810, speed 50.79 f/s, eps 0.02\n",
      "461205: done 268 games, mean reward 7.900, speed 50.39 f/s, eps 0.02\n",
      "462921: done 269 games, mean reward 8.150, speed 50.44 f/s, eps 0.02\n",
      "464609: done 270 games, mean reward 8.390, speed 50.55 f/s, eps 0.02\n",
      "466395: done 271 games, mean reward 8.710, speed 50.73 f/s, eps 0.02\n",
      "468460: done 272 games, mean reward 9.030, speed 50.48 f/s, eps 0.02\n",
      "470550: done 273 games, mean reward 9.280, speed 50.62 f/s, eps 0.02\n",
      "472699: done 274 games, mean reward 9.500, speed 50.58 f/s, eps 0.02\n",
      "475296: done 275 games, mean reward 9.750, speed 50.69 f/s, eps 0.02\n",
      "476931: done 276 games, mean reward 10.040, speed 50.42 f/s, eps 0.02\n",
      "479683: done 277 games, mean reward 10.160, speed 50.33 f/s, eps 0.02\n",
      "481375: done 278 games, mean reward 10.530, speed 50.42 f/s, eps 0.02\n",
      "483134: done 279 games, mean reward 10.850, speed 50.18 f/s, eps 0.02\n",
      "485150: done 280 games, mean reward 11.110, speed 50.65 f/s, eps 0.02\n",
      "486901: done 281 games, mean reward 11.390, speed 50.30 f/s, eps 0.02\n",
      "488904: done 282 games, mean reward 11.600, speed 50.47 f/s, eps 0.02\n",
      "490753: done 283 games, mean reward 11.860, speed 50.14 f/s, eps 0.02\n",
      "492702: done 284 games, mean reward 12.210, speed 49.94 f/s, eps 0.02\n",
      "494366: done 285 games, mean reward 12.390, speed 49.71 f/s, eps 0.02\n",
      "496060: done 286 games, mean reward 12.790, speed 50.47 f/s, eps 0.02\n",
      "498289: done 287 games, mean reward 12.990, speed 50.56 f/s, eps 0.02\n",
      "500198: done 288 games, mean reward 13.210, speed 50.68 f/s, eps 0.02\n",
      "502197: done 289 games, mean reward 13.290, speed 50.10 f/s, eps 0.02\n",
      "504404: done 290 games, mean reward 13.490, speed 50.41 f/s, eps 0.02\n",
      "506241: done 291 games, mean reward 13.590, speed 50.32 f/s, eps 0.02\n",
      "508413: done 292 games, mean reward 13.790, speed 50.41 f/s, eps 0.02\n",
      "510240: done 293 games, mean reward 13.850, speed 50.47 f/s, eps 0.02\n",
      "512187: done 294 games, mean reward 13.990, speed 50.49 f/s, eps 0.02\n",
      "513968: done 295 games, mean reward 14.210, speed 50.39 f/s, eps 0.02\n",
      "516723: done 296 games, mean reward 14.140, speed 50.81 f/s, eps 0.02\n",
      "519010: done 297 games, mean reward 14.120, speed 50.57 f/s, eps 0.02\n",
      "521476: done 298 games, mean reward 14.190, speed 50.69 f/s, eps 0.02\n",
      "523166: done 299 games, mean reward 14.520, speed 50.44 f/s, eps 0.02\n",
      "525033: done 300 games, mean reward 14.580, speed 50.59 f/s, eps 0.02\n",
      "526920: done 301 games, mean reward 14.610, speed 50.42 f/s, eps 0.02\n",
      "528701: done 302 games, mean reward 14.790, speed 50.00 f/s, eps 0.02\n",
      "530387: done 303 games, mean reward 14.890, speed 50.64 f/s, eps 0.02\n",
      "532765: done 304 games, mean reward 15.080, speed 50.65 f/s, eps 0.02\n",
      "534458: done 305 games, mean reward 15.110, speed 49.82 f/s, eps 0.02\n",
      "536670: done 306 games, mean reward 15.070, speed 50.68 f/s, eps 0.02\n",
      "539240: done 307 games, mean reward 14.980, speed 50.25 f/s, eps 0.02\n",
      "541146: done 308 games, mean reward 15.130, speed 50.95 f/s, eps 0.02\n",
      "543206: done 309 games, mean reward 15.150, speed 50.43 f/s, eps 0.02\n",
      "545064: done 310 games, mean reward 15.550, speed 50.53 f/s, eps 0.02\n",
      "547056: done 311 games, mean reward 15.740, speed 50.37 f/s, eps 0.02\n",
      "548906: done 312 games, mean reward 15.790, speed 50.80 f/s, eps 0.02\n",
      "551908: done 313 games, mean reward 15.740, speed 49.99 f/s, eps 0.02\n",
      "554018: done 314 games, mean reward 15.730, speed 50.46 f/s, eps 0.02\n",
      "556205: done 315 games, mean reward 15.730, speed 50.60 f/s, eps 0.02\n",
      "558123: done 316 games, mean reward 15.760, speed 50.67 f/s, eps 0.02\n",
      "560058: done 317 games, mean reward 15.880, speed 50.71 f/s, eps 0.02\n",
      "562176: done 318 games, mean reward 15.890, speed 51.97 f/s, eps 0.02\n",
      "564014: done 319 games, mean reward 15.900, speed 52.25 f/s, eps 0.02\n",
      "565765: done 320 games, mean reward 15.930, speed 52.11 f/s, eps 0.02\n",
      "567712: done 321 games, mean reward 15.900, speed 52.13 f/s, eps 0.02\n",
      "569530: done 322 games, mean reward 15.910, speed 51.52 f/s, eps 0.02\n",
      "571485: done 323 games, mean reward 15.900, speed 52.13 f/s, eps 0.02\n",
      "573306: done 324 games, mean reward 15.910, speed 51.87 f/s, eps 0.02\n",
      "575069: done 325 games, mean reward 16.110, speed 52.45 f/s, eps 0.02\n",
      "576991: done 326 games, mean reward 16.090, speed 52.38 f/s, eps 0.02\n",
      "579341: done 327 games, mean reward 16.060, speed 52.22 f/s, eps 0.02\n",
      "581590: done 328 games, mean reward 16.020, speed 52.41 f/s, eps 0.02\n",
      "583415: done 329 games, mean reward 16.030, speed 52.11 f/s, eps 0.02\n",
      "585701: done 330 games, mean reward 15.980, speed 52.42 f/s, eps 0.02\n",
      "587551: done 331 games, mean reward 15.970, speed 52.11 f/s, eps 0.02\n",
      "589352: done 332 games, mean reward 15.960, speed 52.05 f/s, eps 0.02\n",
      "591015: done 333 games, mean reward 16.000, speed 51.90 f/s, eps 0.02\n",
      "592649: done 334 games, mean reward 16.010, speed 52.49 f/s, eps 0.02\n",
      "594500: done 335 games, mean reward 16.040, speed 52.11 f/s, eps 0.02\n",
      "596331: done 336 games, mean reward 16.020, speed 52.27 f/s, eps 0.02\n",
      "598489: done 337 games, mean reward 16.120, speed 52.58 f/s, eps 0.02\n",
      "600443: done 338 games, mean reward 16.230, speed 52.31 f/s, eps 0.02\n",
      "602266: done 339 games, mean reward 16.240, speed 52.21 f/s, eps 0.02\n",
      "603897: done 340 games, mean reward 16.300, speed 52.36 f/s, eps 0.02\n",
      "605671: done 341 games, mean reward 16.300, speed 52.09 f/s, eps 0.02\n",
      "607494: done 342 games, mean reward 16.350, speed 52.38 f/s, eps 0.02\n",
      "609419: done 343 games, mean reward 16.520, speed 52.32 f/s, eps 0.02\n",
      "611232: done 344 games, mean reward 16.560, speed 52.35 f/s, eps 0.02\n",
      "613060: done 345 games, mean reward 16.610, speed 52.34 f/s, eps 0.02\n",
      "615249: done 346 games, mean reward 16.720, speed 52.32 f/s, eps 0.02\n",
      "617280: done 347 games, mean reward 16.700, speed 52.49 f/s, eps 0.02\n",
      "619457: done 348 games, mean reward 16.660, speed 52.02 f/s, eps 0.02\n",
      "621782: done 349 games, mean reward 16.610, speed 51.75 f/s, eps 0.02\n",
      "623787: done 350 games, mean reward 16.590, speed 51.99 f/s, eps 0.02\n",
      "626064: done 351 games, mean reward 16.560, speed 52.20 f/s, eps 0.02\n",
      "627820: done 352 games, mean reward 16.560, speed 52.07 f/s, eps 0.02\n",
      "629699: done 353 games, mean reward 16.630, speed 52.32 f/s, eps 0.02\n",
      "631424: done 354 games, mean reward 16.730, speed 52.14 f/s, eps 0.02\n",
      "633454: done 355 games, mean reward 16.720, speed 52.37 f/s, eps 0.02\n",
      "635444: done 356 games, mean reward 17.000, speed 52.14 f/s, eps 0.02\n",
      "637261: done 357 games, mean reward 17.040, speed 52.16 f/s, eps 0.02\n",
      "639215: done 358 games, mean reward 17.020, speed 52.42 f/s, eps 0.02\n",
      "641410: done 359 games, mean reward 17.100, speed 52.16 f/s, eps 0.02\n",
      "643288: done 360 games, mean reward 17.100, speed 51.86 f/s, eps 0.02\n",
      "645133: done 361 games, mean reward 17.110, speed 52.02 f/s, eps 0.02\n",
      "646763: done 362 games, mean reward 17.190, speed 51.85 f/s, eps 0.02\n",
      "648554: done 363 games, mean reward 17.220, speed 52.66 f/s, eps 0.02\n",
      "650282: done 364 games, mean reward 17.210, speed 52.43 f/s, eps 0.02\n",
      "652735: done 365 games, mean reward 17.160, speed 52.46 f/s, eps 0.02\n",
      "654905: done 366 games, mean reward 17.210, speed 52.05 f/s, eps 0.02\n",
      "656940: done 367 games, mean reward 17.160, speed 52.31 f/s, eps 0.02\n",
      "658953: done 368 games, mean reward 17.170, speed 52.46 f/s, eps 0.02\n",
      "660811: done 369 games, mean reward 17.140, speed 52.34 f/s, eps 0.02\n",
      "662666: done 370 games, mean reward 17.130, speed 52.42 f/s, eps 0.02\n",
      "664604: done 371 games, mean reward 17.110, speed 52.20 f/s, eps 0.02\n",
      "666523: done 372 games, mean reward 17.110, speed 52.29 f/s, eps 0.02\n",
      "668275: done 373 games, mean reward 17.150, speed 52.53 f/s, eps 0.02\n",
      "670141: done 374 games, mean reward 17.190, speed 51.90 f/s, eps 0.02\n",
      "671940: done 375 games, mean reward 17.280, speed 51.20 f/s, eps 0.02\n",
      "673883: done 376 games, mean reward 17.270, speed 48.62 f/s, eps 0.02\n",
      "675781: done 377 games, mean reward 17.360, speed 48.69 f/s, eps 0.02\n",
      "677472: done 378 games, mean reward 17.360, speed 48.00 f/s, eps 0.02\n",
      "679356: done 379 games, mean reward 17.340, speed 46.61 f/s, eps 0.02\n",
      "681455: done 380 games, mean reward 17.320, speed 49.38 f/s, eps 0.02\n",
      "683684: done 381 games, mean reward 17.300, speed 44.48 f/s, eps 0.02\n",
      "685373: done 382 games, mean reward 17.330, speed 44.62 f/s, eps 0.02\n",
      "687280: done 383 games, mean reward 17.340, speed 51.34 f/s, eps 0.02\n",
      "689099: done 384 games, mean reward 17.360, speed 51.98 f/s, eps 0.02\n",
      "690793: done 385 games, mean reward 17.360, speed 52.04 f/s, eps 0.02\n",
      "692621: done 386 games, mean reward 17.330, speed 52.16 f/s, eps 0.02\n",
      "694803: done 387 games, mean reward 17.370, speed 51.78 f/s, eps 0.02\n",
      "696557: done 388 games, mean reward 17.370, speed 52.18 f/s, eps 0.02\n",
      "698639: done 389 games, mean reward 17.360, speed 52.27 f/s, eps 0.02\n",
      "700524: done 390 games, mean reward 17.390, speed 52.17 f/s, eps 0.02\n",
      "702842: done 391 games, mean reward 17.330, speed 52.34 f/s, eps 0.02\n",
      "705232: done 392 games, mean reward 17.310, speed 52.10 f/s, eps 0.02\n",
      "707118: done 393 games, mean reward 17.310, speed 51.83 f/s, eps 0.02\n",
      "709107: done 394 games, mean reward 17.310, speed 52.41 f/s, eps 0.02\n",
      "711020: done 395 games, mean reward 17.300, speed 51.86 f/s, eps 0.02\n",
      "713026: done 396 games, mean reward 17.340, speed 52.50 f/s, eps 0.02\n",
      "714804: done 397 games, mean reward 17.410, speed 52.49 f/s, eps 0.02\n",
      "716677: done 398 games, mean reward 17.490, speed 52.39 f/s, eps 0.02\n",
      "718486: done 399 games, mean reward 17.470, speed 52.11 f/s, eps 0.02\n",
      "720194: done 400 games, mean reward 17.500, speed 52.28 f/s, eps 0.02\n",
      "722345: done 401 games, mean reward 17.530, speed 51.98 f/s, eps 0.02\n",
      "724276: done 402 games, mean reward 17.520, speed 52.56 f/s, eps 0.02\n",
      "726122: done 403 games, mean reward 17.520, speed 51.91 f/s, eps 0.02\n",
      "727942: done 404 games, mean reward 17.620, speed 52.25 f/s, eps 0.02\n",
      "730459: done 405 games, mean reward 17.550, speed 52.19 f/s, eps 0.02\n",
      "732597: done 406 games, mean reward 17.550, speed 52.41 f/s, eps 0.02\n",
      "734227: done 407 games, mean reward 17.660, speed 52.00 f/s, eps 0.02\n",
      "736240: done 408 games, mean reward 17.640, speed 52.05 f/s, eps 0.02\n",
      "738264: done 409 games, mean reward 17.630, speed 52.19 f/s, eps 0.02\n",
      "739895: done 410 games, mean reward 17.650, speed 52.35 f/s, eps 0.02\n",
      "741525: done 411 games, mean reward 17.700, speed 52.11 f/s, eps 0.02\n",
      "743506: done 412 games, mean reward 17.680, speed 52.03 f/s, eps 0.02\n",
      "745428: done 413 games, mean reward 17.850, speed 52.01 f/s, eps 0.02\n",
      "747455: done 414 games, mean reward 17.850, speed 52.27 f/s, eps 0.02\n",
      "749364: done 415 games, mean reward 17.880, speed 52.29 f/s, eps 0.02\n",
      "751373: done 416 games, mean reward 17.850, speed 52.10 f/s, eps 0.02\n",
      "753236: done 417 games, mean reward 17.860, speed 52.15 f/s, eps 0.02\n",
      "754964: done 418 games, mean reward 17.890, speed 52.00 f/s, eps 0.02\n",
      "756596: done 419 games, mean reward 17.910, speed 51.81 f/s, eps 0.02\n",
      "758858: done 420 games, mean reward 17.870, speed 52.19 f/s, eps 0.02\n",
      "760491: done 421 games, mean reward 17.900, speed 52.34 f/s, eps 0.02\n",
      "762361: done 422 games, mean reward 17.920, speed 52.14 f/s, eps 0.02\n",
      "764059: done 423 games, mean reward 17.950, speed 52.30 f/s, eps 0.02\n",
      "765850: done 424 games, mean reward 17.950, speed 52.28 f/s, eps 0.02\n",
      "767671: done 425 games, mean reward 17.950, speed 52.28 f/s, eps 0.02\n",
      "769369: done 426 games, mean reward 17.980, speed 51.79 f/s, eps 0.02\n",
      "771033: done 427 games, mean reward 18.030, speed 52.16 f/s, eps 0.02\n",
      "Solved in 771033 frames!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "f = open('C:/Users/Kelvin/Desktop/reinforcement learning/Chapter 7/dqn_double_output.txt', 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement",
   "language": "python",
   "name": "reinforcement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
